% Chapter Template

\chapter{Implementation \& Evaluation} % Main chapter title

\label{Chapter5} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 5. \emph{Experiment Implementation \& Evaluation}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
\section{Introduction}
This chapter will present the implementation of the experiments to evaluate the use of macro-economic features for predicting SME defaults. The predictive capability of customers spending behaviour, personal customer default rates, SME default rates and Census data  will be analysed and discussed.

The experiments in this research are sequential meaning results from one experiment are used in the following experiment. Therefore results will also be discussed and evaluated in this section.

A benchmark predictive model will be built in SAS and R based on historical scorecard features. This will be used to make fair comparisons to the results from the experiments.


\section{Benchmark Models}\label{sec:benchModels}
As mentioned in previous section when building predictive models its is essential to have a baseline or benchmark model to compare your experiments to. Therefore benchmark regression models have been built in R and SAS that will be used to make comparisons to experiments in this chapter. Regression was chosen because of its success in experiments in Section \ref{sec:benchFeature} and its wide use in industry. The models have been trained for both R and SAS using a 70\% stratified sample dataset with 30\% being kept for holdout which will be used for testing. Results may vary from both R and SAS due to varying samples in each application and algorithms will be slightly different but they should relatively close. This will not impact analysis of comparing experiments as experiments in R will be compared to the benchmark from R and likewise for comparisons in SAS. The AUC will the performance measure of choice for evaluating the well the model fits over all possible thresholds. As the AUC does not give us the accuracy of the model a specific threshold we will also use the recall, specificity and balanced accuracy(BA). The threshold used is based on fine tuning of the parameters testing using a validation dataset in Section \ref{sec:benchFeature}. The breakdown of the training and test for the benchmark model datasets and their target class distribution can be shown in Table \ref{table:benchmark_holdout_train_test}.

\begin{table}[H]
	\centering\
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l r r r r}
			\hline
			\textbf{Model} &  \textbf{Dataset} & \textbf{\# Bad} & \textbf{\# Good} & \textbf{\# Observations} & \textbf{Good:Bad} \\
			\hline
			Previous Delinquency & Training       & 483 & 1,565 & 2,048 & 76:24\\
			          & Test & 245 & 633 & 878 & 72:28\\\hline
			\textbf{Previous Previous Delinquency}     & \textbf{Total} & \textbf{728} & \textbf{2,198} & \textbf{2,926} & \textbf{75:25} \\
			\hline
			No Previous Delinquency & Training & 474 & 16,435 & 16,909 & 97:03 \\ 
			          & Test & 177 & 7,070 & 7,247 & 97:03 	\\\hline
			\textbf{No Previous Delinquency}     & \textbf{Total} & \textbf{651} & \textbf{23,505} & \textbf{24,156} & \textbf{97:03} \\
			\hline
			\textbf{Total } 	&     	     & \textbf{1,379} & \textbf{25,703} & \textbf{27,082} & \textbf{95:05}\\ \hline
		\end{tabular}
	}
	\caption{Breakdown Holdout Training/Test Dataset \\for Benchmark Models}
	\label{table:benchmark_holdout_train_test}
\end{table}

The threshold used for performance measuring is based on fine tuning of the parameters testing using a validation dataset in Section \ref{sec:benchFeature}. The results from the benchmark models can be found in Table \ref{table:benchmodel} below.

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{\footnotesize
		\begin{tabular}{l l l r r r r}
			\hline
			\textbf{Model} & \textbf{Dataset} & \textbf{Software} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_Bench\_R} & Previous Delinquency & R & 0.542 & 0.696 & 0.619 & 0.654   \\ 
			\textit{PD\_Bench\_SAS} & Previous Delinquency & SAS & 0.529 & 0.616 & 0.573 & 0.615   \\ \hline
			\textit{NPD\_Bench\_R} & No Previous Delinquency & R & 0.525 & 0.739 & 0.632 & 0.671   \\ 
			\textit{NPD\_Bench\_SAS} & No Previous Delinquency & SAS & 0.492 & 0.748 & 0.620 & 0.654   \\ \hline
		\end{tabular}
	}
	\caption{Benchmark Model Results for Experiment Comparison}
	\label{table:benchmodel}
\end{table}

Models in this this section will be aliased for ease of reading, for example the benchmark models will be referred to as \textit{PD\_Bench\_R}, \textit{PD\_Bench\_SAS}, \textit{NPD\_Bench\_R} and \textit{NPD\_Bench\_SAS} which can be seen in Table \ref{table:benchmodel} above. The results found here are consistent with the evaluations completed in Chapter \ref{Chapter4} which guarantees we have good benchmarks to compare the results in the experiment in this chapter to.


\section{Correlation Analysis}
Correlation matrix is a very simple and powerful way of analysing the relationship of predictive features with each other and the target features. Including highly correlated predictive features has the potential to throw off or fool your predictive model potentially causing misleading results. The Pearson correlation coefficient is a common measure used to test your data to check this relationship and will be deployed in this experiment. The correlation tests are ran separately on each category of features created as part of this experiment e.g. \textit{CSO Features by ED \& LA}, \textit{SME Default Trends by ED \& LA}, \textit{Homeloan and Personal Loan Default Trends by ED \& LA}, \textit{Transactions Behaviour by ED \& LA}, and \textit{Binned SME Defaults Rates by ED and LA}. Fig. \ref{fig:unbal_corr_analysis} shows a subset of the results demonstrating correlation scores between the experiment features categories with a full breakdown of the results available in Appendix \ref{AppendixB} where a correlation score coloured red represents a very strong positive correlation between features and blue a very low negative correlation.

\begin{figure}[H]
	\centering
 	\begin{subfigure}[b]{0.32\textwidth}
 		\captionsetup{font=scriptsize}
 		\includegraphics[width=\textwidth,height=2.75cm]{CSO_Correlation_Analysis}
 		\caption{CSO Features by ED \& LA\\}
 		\label{fig:CSOCorrelation}
 	\end{subfigure}
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{SME_Arrears_Trends_Correlation_Analysis_Subset}
		\caption{SME Default Trends \\by ED \& LA}\label{fig:smeArrearsCorrelation}
	\end{subfigure} 
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Personal_Arrears_Ratio}
		\caption{Homeloan and Personal Loan Default Trends by ED \& LA}
		\label{fig:personalArrearsCorrelation}
	\end{subfigure} 
	\medskip
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Visa_Debit_Correlation_Analysis_Subset}
		\caption{Transactions Behaviour \\by ED \& LA }\label{fig:transVisaCorrelation}
	\end{subfigure} ~\quad
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Grouped_Features_Correlation_Analysis_Subset}
		\caption{Binned SME Defaults Rates \\by ED and LA\\}
		\label{fig:groupedFeaturesCorrelation}
	\end{subfigure}
	\caption{Correlation Analysis}
	\label{fig:unbal_corr_analysis}
\end{figure}

There is a high level of correlation between among many of the variables. It was decided that any features that had a correlation score of 0.80 would be candidate features for removal. For features that were this highly correlated the feature scoring the lowest bivariate correlation to the target feature was removed, ensuring the variable which had the strongest relationship with the target class was prioritised and kept for further predictions. The a subset of the results after this feature reduction process can be found in Fig. \ref{unbal_corr_analysis_filtered} with a full set of results available in Appendix \ref{AppendixC}. 

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{CSO_Correlation_Analysis}
		\caption{CSO Features by ED \& LA\\}
		\label{fig:CSOCorrelation}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{SMETrendsCorrSub}
		\caption{SME Default Trends \\by ED \& LA}\label{fig:SMETrendsCorrSub}
	\end{subfigure} 
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{PersonalTrendFull}
		\caption{Homeloan and Personal Loan Default Trends by ED \& LA}
		\label{fig:PersonalTrendFull}
	\end{subfigure} 
	\medskip
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{TransactionCorrSub}
		\caption{Transactions Behaviour \\by ED \& LA }\label{fig:TransactionCorrSub}
	\end{subfigure} ~\quad
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{GroupedCorrSub}
		\caption{Binned SME Defaults Rates \\by ED and LA\\}
		\label{fig:GroupedCorrSub}
	\end{subfigure}
	\caption{Correlation Analysis after highly correlated features have been removed}
	\label{fig:unbal_corr_analysis_filtered}
\end{figure}

We then analyse the variables that are most correlated with the target to see if included in the prediction model how well it performs, results from this analysis are demonstrated in Fig. \ref{fig:Correlation Analysis} below.

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{CorrelationChart}
	\caption{Most correlated features with target variable}
	\label{fig:Correlation Analysis}
\end{figure}

Table \ref{table:CorrModelResults} below shows the results from including the top 5, 10, 15, 20 correlated features after the correlation analysis as per the Table \ref{table:CorrModelResults}. 

\begin{table}[H]
\centering
\small
		\begin{tabular}{l r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_Cor5\_R}  & 0.534 & 0.669 & 0.602 & 0.654   \\ 
			\textit{PD\_Cor10\_R} & 0.556 & 0.679 & 0.618 & 0.658  \\ 
			\textit{PD\_Cor15\_R} & 0.594 & 0.690 & 0.642 & 0.665  \\
			\textit{PD\_Cor20\_R} & 0.561 & 0.698 & 0.630 & 0.665  \\\hline 
			
			\textit{NPD\_Cor5\_R}  & 0.525 & 0.743 & 0.634 & 0.671   \\ 
			\textit{NPD\_Cor10\_R} & 0.555 & 0.725 & 0.640 & 0.677  \\ 
			\textit{NPD\_Cor15\_R} & 0.538 & 0.723 & 0.630 & 0.680  \\
			\textit{NPD\_Cor20\_R} & 0.549 & 0.731 & 0.640 & 0.676  \\\hline 
		\end{tabular}
	\caption{Models from Correlation Feature Selection}
	\label{table:CorrModelResults}
\end{table}

For each model result the AUC will be used to measure the overall accuracy of the model while Recall, Specificity, Balanced Accuracy will be recorded to evaluate how the model performs at specified threshold. These results will be evaluated against the benchmark results in a later section of the chapter.


\section{Feature Selection}
As mentioned in the research literature in Section \ref{sec2:featureSection} feature selection is important when building a predictive model for a reasons such as reducing the complexity of the model, mitigating the risk of over-fitting, overhead involved with having to understand and maintain a larger number of features, model training and computation time and when you need evaluate/explain your results. In summary simpler in the majority of cases is better.

Therefore a number of feature selection process will be experimented with in this section to try and identify the features that are of key importance, reducing the complexity of the model and identifying the important features. The two process that will be used are \textit{Information Gain Feature Importance} and \textit{Random Forest Feature Importance}

The feature selection process of this experiment was only carried out on the training partitions of the dataset.

\subsection{Information Gain Feature Importance}
Information gain is an approach that utilises measures commonly seen when a decision tree model is being trained (See Section \ref{decTrees}). It calculates and ranks features using entropy and information gain. For each experiment the existing scorecard features and macro-economic features as part of this experiment were analysed. Since we are only interested in the identifying the importance of macro-economic features as part of this research the existing features were stripped out of the result as we cannot tamper with the benchmark model dataset as this could lead to misleading results. Due to the risks previously discussed with having too many features in your training dataset only the top 20 features will be included in models to be trained along with the existing scorecard features as part of this experiment.

\subsubsection{Information Gain for Previous Delinquency Data} \label{IGPDExper}
Addressing the \textit{Previous Delinquency} dataset the information gain was calculated for each of the existing scorecard features and macro-economic features. Details of the feature importance can be seen in Fig. \ref{fig:DelinqInformationGainAnalysis}

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{DelinqInformationGainAnalysis}
	\caption{Top 20 Macro-Economic Feature calculated by \\ Information Gain on Previous Delinquency Dataset}
	\label{fig:DelinqInformationGainAnalysis}
\end{figure}

As can be seen in Fig. \ref{fig:DelinqInformationGainAnalysis} the results from this test are not very promising. The information gain is very small for features which suggests the features were not any better at explaining the target feature than the existing scorecard features. 

The features that show strongest performance \textit{ED\_LOAN}, \textit{ED\_HOME} as based on default rates of personal loan and homeloan customers at electoral division. This intuitively could makes sense i.e. if people in an electoral division are struggling with their loan and mortgage repayments they are less likely to spend money in businesses in that area. \textit{ED\_LOWER\_THAN\_UPPER\_SECONDARY}, \textit{ED\_UNEMPLOYMENT} and \textit{ED\_NON\_MANUALOCCUPATION} relates to features created in the census data to with low levels of education, high unemployment rate which again intuitively at least make sense. If there are people in an area with low levels of education and therefore cant get work they're less likely to spend money on businesses in that area.

Despite the low information gain of all macro economic feature in the results above we re-train and test the model including the most important features from the information gain calculation. Separate models will be trained using the top 5, 10, 15 and 20 features from the information gain calculation. Table \ref{table:InfoGainPDModelResults} details the results for the re-trained model on the test data using the features selected as part of the information gain calculation.

\begin{table}[H]
\centering
\small
		\begin{tabular}{l r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA*} & \textbf{AUC}  \\ \hline
			\textit{PD\_Bench\_R} & 0.542 & 0.696 & 0.619 & \cellcolor{green!25}0.654 \\ \hline
			\textit{PD\_IG5\_R} & 0.540 & \cellcolor{green!25}0.715 & 0.627 & 0.652   \\ 
			\textit{PD\_IG10\_R} & \cellcolor{green!25}0.548 & 0.693 & 0.621 & 0.649  \\ 
			\textit{PD\_IG15\_R} & 0.536 & 0.690 & 0.613 & 0.650  \\
			\textit{PD\_IG20\_R} & 0.544 & 0.711 & \cellcolor{green!25}0.628 & 0.651 \\\hline 
		\end{tabular}
	\caption{Previous Delinquency Model results when most important \\Macro-Economic features calculated using Information Gain were included in training.\\
		*BA = Balanced Accuracy}
	\label{table:InfoGainPDModelResults}
\end{table}

The results from including macro-economic features based on the information gain feature importance are compared against the benchmark model (\textit{PD\_Bench\_R})built in Section \ref{sec:benchModels}. \textit{PD\_IG5\_R} will relate to the model that was trained using the top 5 features from the information gain calculation, \textit{PD\_IG10\_R} is the top 10 features, \textit{PD\_IG15\_R} is the top 15 features, \textit{PD\_IG20\_R} is the top 20 features.The highest results for each performance metric are highlighted in green.

None of the models trained in this experiment performed better under the AUC which identifies the best model accuracy of the model over all possible thresholds. The \textit{PD\_IG5\_R}, \textit{PD\_IG20\_R} models have a larger specificity than the benchmark meaning the model was able to identify a larger proportion of the negative cases correctly. \textit{PD\_IG10\_R} and \textit{PD\_IG20\_R} both returned higher balanced accuracy and recall. Higher recall means both models predicted higher percentage of the positive class correctly. Although this is an improvement on the benchmark models the results are not markedly better and would need further investigation to test for statistical significance.

\subsubsection{Information Gain for No Previous Delinquency Data}\label{IGNPDExper}
Addressing the \textit{No Previous Delinquency} dataset the information gain was calculated for each of the existing scorecard features and macro-economic features. Details of the feature importance can be seen in Fig. \ref{fig:NoDelinqInformationGainAnalysis}

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{NoDelinqInformationGainAnalysis}
	\caption{Top 20 Macro-Economic Feature calculated by \\ Information Gain on No Previous Delinquency Dataset}
	\label{fig:NoDelinqInformationGainAnalysis}
\end{figure}

It can be seen in Fig. \ref{fig:NoDelinqInformationGainAnalysis} the results from this test are not very promising as with the previous experiment. The information gain is very small for features which suggests the features were not any better at explaining the target feature than the existing scorecard features. 

The features that show strongest performance as based on SME default rates in an electoral division (See Table \ref{SMEDefaultBehaviourDataset}). The features that show strongest performance \textit{ED PERCENT 30 06 2014}, \textit{ED CNT 1 30 06 2014} as based on the default rate of SME customers and the number of SME customers in default at an electoral division. \textit{DIFF 12 2013} to \textit{ED DIFF 06 2012 ED} are based on the percentage change of default rates. Again these intuitively for predicting either the negative of positive class. If defaulting is trending up in area they could be indicative of further defaulters, likewise if default rate is or going down consumer spend must be good in these areas and there is smaller risk of default is the future

Again despite the low information gain of all macro economic feature in the results above we re-train and test the model including the most important features from the information gain calculation. Separate models will be trained using the top 5, 10, 15 and 20 features from the information gain calculation. Table \ref{table:InfoGainNPDModelResults} details the results for the re-trained model on the test data using the features selected as part of the information gain calculation.


\begin{table}[H]
\centering
\small
		\begin{tabular}{l r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA*} & \textbf{AUC}  \\ \hline
			\textit{NPD\_Bench\_R} & 0.525 & \cellcolor{green!25}0.739 & 0.632 & \cellcolor{green!25}0.671   \\ \hline
			\textit{NPD\_IG5\_R} & \cellcolor{green!25}0.542 & 0.736 & \cellcolor{green!25}0.639 & 0.667   \\ 
			\textit{NPD\_IG10\_R} & 0.536 & 0.736 & 0.636 & 0.667  \\ 
			\textit{NPD\_IG15\_R} & 0.520 & 0.732 & 0.626 & 0.663 \\
			\textit{NPD\_IG20\_R} &  0.508 & 0.730 & 0.619 & 0.665  \\\hline 
		\end{tabular}
	\caption{No Previous Delinquency Model results when most important \\Macro-Economic features calculated using Information Gain were included in training.\\
		*BA = Balanced Accuracy}
	\label{table:InfoGainNPDModelResults}
\end{table}

The results from including macro-economic features based on the information gain feature importance are compared against the benchmark model (\textit{PD\_Bench\_R})built in Section \ref{sec:benchModels}. \textit{NPD\_IG5\_R} will relate to the model that was trained using the top 5 features from the information gain calculation, \textit{NPD\_IG10\_R} is the top 10 features, \textit{NPD\_IG15\_R} is the top 15 features, \textit{NPD\_IG20\_R} is the top 20 features. The highest results for each performance metric are highlighted in green.

None of four models (\textit{NPD\_IG5\_R}, \textit{NPD\_IG10\_R}, \textit{NPD\_IG15\_R}, \textit{NPD\_IG20\_R}) outperformed the benchmark model in terms of the AUC which identifies the best model based over all possible thresholds. \textit{NPD\_IG5\_R} performed the strongest by scoring a highest recall and balanced accuracy of models compared. This means it was identifying a higher percentage of the positive class correctly than the benchmark. Although this is an improvement on the benchmark models the results are not markedly better and would need further investigation to test for statistical significance.

\subsection{Random Forest Feature Importance}
A random forest is a very common and popular method of building a predictive modelling. It is an extension of the previously discussed decision tree (See Section \ref{decTrees}). The approach is to create large number of decision trees and then combine them together to make a classification, hence why its called a forest. For each decision tree random subsets of the full training set for each decision tree are used, hence random. Hence this is why it is called a random forest. It is also widely in the process of feature selection every build $n$ number of trees in your forest and evaluate how much each feature improves the classification over the entire forest. 

For both the \textit{Previous Delinquency} and \textit{No Previous Delinquency} experiments in this section 1000 trees will be created to evaluate the importance of all the features. As with the previous experiment since we are only
interested in the identifying the importance of macro-economic features as part of this
research the existing features were stripped out of the results as tampering with the benchmark model dataset as this could lead to misleading results. Due to the risks previously discussed
with having too many features in your training dataset only the top 20 features will be
included in models to be trained along with the existing scorecard features as part of this experiment.


\subsubsection{Feature Importance for Previous Delinquency Data using Random Forests}\label{RFPDExper}
Addressing the size of the Previous Delinquency dataset random forest feature importance was calculated for
each of the existing scorecard features and macro-economic features. Details of the feature importance can be seen in Fig. \ref{fig:DelinqRandomForestsAnalysis} below

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{DelinqRandomForestsAnalysis}
	\caption{Top 20 Macro-Economic Feature calculated by \\
		Random Forest Feature Importance on Previous Delinquency Dataset}
	\label{fig:DelinqRandomForestsAnalysis}
\end{figure}

It can be seen in Fig. \ref{fig:DelinqRandomForestsAnalysis} that features associated with discretionary and non discretionary (See Table \ref{discretionarySpend}) perform strongly in this analysis as 17 of the top 20 features are represented by this dataset. It is worth noting that all of there features are at an electoral division level opposed local authority which signify there has been some shift in customer discretionary and non discretionary spend at the geographic level that is useful for predicting SME defaults or non-defaults. As with the previous experiment calculating information gain  (See Fig. \ref{fig:NoDelinqInformationGainAnalysis}) the SME default rates at an electoral division also included in the top 20 most important features.

Using these results separate models will be trained using the top 5, 10, 15 and 20 features from
the random forest feature importance algorithm. Table \ref{table:RFPDModelResults} details the results for the re-trained model
on the test data using the features selected as part of the random forest feature ranking

\begin{table}[H]
\centering
\small
		\begin{tabular}{l r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA*} & \textbf{AUC}  \\ \hline
			\textit{PD\_Bench\_R} & 0.542 & 0.696 & 0.619 & 0.654 \\ \hline
			\textit{PD\_RF5\_R} & 0.548 & 0.692 & 0.620 & \cellcolor{green!25}0.662   \\ 
			\textit{PD\_RF10\_R} & \cellcolor{green!25}0.556 & \cellcolor{green!25}0.703 & \cellcolor{green!25}0.630 & 0.655  \\ 
			\textit{PD\_RF15\_R} & 0.548 & 0.698 & 0.623 & 0.654  \\
			\textit{PD\_RF20\_R} & 0.535 & 0.698 & 0.617 & 0.651  \\\hline 
		\end{tabular}

	\caption{Previous Delinquency Model results when most important\\
Macro-Economic features calculated using Random Forest feature \\selection were included in training.
\\ *BA = Balanced Accuracy}
	\label{table:RFPDModelResults}
\end{table}

The results from including macro-economic features based on the random forest feature selection are compared against the benchmark model (\textit{PD\_Bench\_R}) built in Section \ref{sec:benchModels}. \textit{PD\_RF5\_R} will relate to the model that was trained using the top 5 features from the information gain calculation, \textit{PD\_RF10\_R} is the top 10 features, \textit{PD\_RF15\_R} is the top 15 features, \textit{PD\_RF20\_R} is the top 20 features. The highest results for each performance metric are highlighted in green.

Results are promising from this experiment, the benchmark model did not outperform the models ran as part of this experiment for any performance measure. \textit{PD\_RF10\_R} demonstrated  very promising results returning a better result for every performance measure compared to the benchmark model. The only result it was not optimal in was the AUC which scored highest in the \textit{PD\_RF20\_R} model. Although the \textit{PD\_RF10\_R} is outperforming the benchmark on all measures the results are not markedly better and would need further investigation to test for statistical significance.

\subsubsection{Feature Importance for No Previous Delinquency Data using Random Forests}\label{RFNPDExper}

Addressing the size of the No Previous Delinquency dataset random forest feature importance was calculated for
each of the existing scorecard features and macro-economic features. Details of the feature importance can be seen in Fig. \ref{fig:NoDelinqRandomForestsAnalysis} below

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{NoDelinqRandomForestsAnalysis}
	\caption{Top 20 Macro-Economic Feature calculated by \\
		Random Forest Feature Importance on No Previous Delinquency Dataset}
	\label{fig:NoDelinqRandomForestsAnalysis}
\end{figure}


It can be seen in Fig. \ref{fig:NoDelinqRandomForestsAnalysis} that features associated with discretionary and non discretionary (See Table \ref{discretionarySpend}) perform strongly in this analysis as 17 of the top 20 features are represented by this dataset which is consistent with the previous random forest feature selection experiment. Again this could be due to spending shift by customers in those electoral divisions going up or down. Again electoral division features are completely dominant in comparison the local authority based features across all top 20 features selected. Lower education rates and occupation rate appear in the top 20 features as they did in information gain experiment in (See Fig. \ref{fig:DelinqInformationGainAnalysis} and Fig. \ref{fig:NoDelinqInformationGainAnalysis}).

Using these results separate models will be trained using the top 5, 10, 15 and 20 features from
the random forest feature importance algorithm. Table \ref{table:RFNPDModelResults} details the results for the re-trained model
on the test data using the features selected as part of the random forest feature ranking

\begin{table}[H]
\centering
\small
		\begin{tabular}{l  r r r r}
\hline
\textbf{Model}  & \textbf{Recall} & \textbf{Specificity} & \textbf{BA*} & \textbf{AUC}  \\ \hline
\textit{NPD\_Bench\_R} & 0.525 & \cellcolor{green!25}0.739 & \cellcolor{green!25}0.632 & \cellcolor{green!25}0.671   \\ \hline
\textit{NPD\_RF5\_R}  & \cellcolor{green!25}0.526 & 0.733 & 0.630 & 0.670   \\ 
\textit{NPD\_RF10\_R} & 0.497 & 0.734 & 0.615 & 0.670 \\ 
\textit{NPD\_RF15\_R} & 0.473 & 0.732 & 0.602 & 0.664  \\
\textit{NPD\_RF20\_R} & 0.485 & 0.730 & 0.608 & 0.664  \\\hline 
		\end{tabular}

	\caption{No Previous Delinquency Model results when most important\\
		Macro-Economic features calculated using Random Forest feature \\selection were included in training.
		\\ *BA = Balanced Accuracy}
	\label{table:RFNPDModelResults}
\end{table}

The results from including macro-economic features based on the random forest feature selection are compared against the benchmark model (\textit{PD\_Bench\_R}) built in Section \ref{sec:benchModels}. \textit{NPD\_RF5\_R} will relate to the model that was trained using the top 5 features from the information gain calculation, \textit{NPD\_RF10\_R} is the top 10 features, \textit{NPD\_RF15\_R} is the top 15 features, \textit{NPD\_RF20\_R} is the top 20 features. The highest results for each performance metric are highlighted in green.

Results from the macro economic based predictive models are not very promising from this experiment as the benchmark model outperforms the others across all performance measures, apart from \textit{NPD\_RF5\_R} which performs slightly better on recall than the benchmark model \textit{NPD\_Bench\_R}. \textit{NPD\_RF5\_R} is comparatively very close across all performance measure. Interestingly with the introduction 15 and 20 features in \textit{NPD\_RF15\_R} and \textit{NPD\_RF20\_R} the models results get considerably compared to the introduction of 5 and 10 features \textit{NPD\_RF5\_R} and \textit{NPD\_RF10\_R}.



\section{Coarse Selection}
As mentioned in Section \ref{sec:binning}, coarse selection or binning is a process where you transform your features continuous or nominal into a simplified structure of just a number of categories. There are many benefits which have been noted in the literature for using coarse selection such as handling missing data and outliers and increasing robustness by reducing risks or over-fitting. A standard approach is to split each feature into approximately three to six groups or bins. This is done by finding cut-points in the data and evaluating the relationship with target feature using Weight of Evidence (WoE) and the information value is used to compare the predictive capability of grouped features.

For both the \textit{Previous Delinquency} and \textit{No Previous Delinquency} dataset experiments in this section coarse selection will applied to all the macro economic features where we will look to transform each feature into a much more simplified feature which will have up to 6 groups or bins. Coarse selection will not be applied to existing model features as this would not allow for a fair comparison with the benchmark model and could lead to misleading results. It also worth noting that coarse selection must only be run on the training dataset as running it on the full dataset would lead to anachronistic group features.


\subsubsection{Coarse Selection for Previous Delinquency Data}
Coarse selection will be run on the macro-economic Previous Delinquency features. As mentioned previous a maximum of 6 bins/groups per feature will be created as per the literature. As with previous experiments in this chapter the top 5, 10, 15, 20 grouped features will be added to the existing Previous Delinquency model feature set and models will be generated. The results from these models will then be compared and evaluated against the results from the benchmark model.

Coarse selection is applied to the previous delinquency macro-economic features, results are shown in Fig. \ref{fig:PDCoarseSelectionVariableImportanceInformationGain}

\begin{figure}[H]
	\includegraphics[width=.9\textwidth,center]{PDCoarseSelectionVariableImportanceInformationGain}
	\caption{Feature ranking by Information Value after coarse selection \\is applied to the macro-economic features of the Previous Delinquency dataset}
	\label{fig:PDCoarseSelectionVariableImportanceInformationGain}
\end{figure}

The results from the coarse selection are interesting, there are seven binned features based on local authority and thirteen based on electoral division. All the other experiments so far feature importance have been dominated completely by electoral division features. Most (14) of the binned features are sourced from source from the discretionary/non-discretionary spend dataset  (See Table \ref{discretionarySpend}). The top rated feature \textit{DIFF PERCENT 06 2012 ED} is the difference in SME default rates at June 2012 and at the observation point June 2014. It is worth noting that the top 5 or 6 binned features appear to be much more predictive based on the information value than the rest. This illustrated in in Fig. \ref{fig:Information Value using SAS Previous Delinquency Features}.

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{PreviousDelinq_InformationGain_InteractiveGrouping}
	\caption{Barplot of feature ranking by Information Value after coarse selection \\is applied to the macro-economic features of the Previous Delinquency dataset}
	\label{fig:Information Value using SAS Previous Delinquency Features}
\end{figure}

If you look to the left the barplot above you can see that there 5 or 6 features which have a much higher information value than the rest.


Fig. \ref{fig:Interactive Grouping Diff Percent 06 2012 ED} demonstrates the results of the top 5 macro economic binned features.
\begin{figure}[H]
	\includegraphics[width=1\textwidth,center]{ExampleInteractiveGrouping}
	\caption{Top 5 binned features results based on information value after coarse \\selection is applied to the macro-economic features of the Previous Delinquency dataset
	\\ Top 5 Binned Features: \textit{DIFF PERCENT 06 2012 ED, ED LIVE LST MTH VS 3MTH AVG LIVE MEAN, LA LIVE LST MTH VS 12MTH AVG LIVE MEAN, ED DISC LST 3MTH MED VS PRV 3MTH MED SPEND MEDIAN, ED LIVE LST MTH VS 6MTH AVG LIVE MEAN}}
	\label{fig:Interactive Grouping Diff Percent 06 2012 ED}
\end{figure}

Fig. \ref{fig:Interactive Grouping Diff Percent 06 2012 ED} shows demonstrates how the features now look in their binned nominal state. Optimal cutpoint are decided using WoE and information value as discussed earlier. The group highlighted in the chart above shows the rules for building that bin which is highlighted the equation below
\[
\text{Group 4(Event Rate 37.75) Values} = 0.05 \leq \text{\textit{DIFF PERCENT 06 2012 ED}} < 0.16
\]
It saying that for all the features values greater than or equal to $0.05$ and less than $0.16$ assign then to bin 4, the event rate details what percentage of the times it happens in this example it 37.75\% of the time. It can be observed that all the features in Fig. \ref{fig:Interactive Grouping Diff Percent 06 2012 ED} got transformed into features of 5 bins which would have been the optimal result based on WoE and information value.

Using these results separate models will be trained using the top 5, 10, 15 and 20 features from
the coarse classification ranked on information value. Table \ref{table:CoarsePDModelResults} details the results for the re-trained model
on the test data using the features selected as part of the coarse classification process

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{l r r r r}
		\hline
		\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA*} & \textbf{AUC}  \\ \hline
		\textit{PD\_Bench\_SAS} & 0.529 & 0.616 & 0.573 & 0.615 \\ \hline
		\textit{PD\_Coarse5\_SAS}  & 0.543 & \cellcolor{green!25}0.645 & \cellcolor{green!25}0.594 & \cellcolor{green!25}0.627   \\ 
		\textit{PD\_Coarse10\_SAS} & \cellcolor{green!25}0.552 & 0.618 & 0.585 & 0.619  \\ 
		\textit{PD\_Coarse15\_SAS} & 0.511 & 0.618 & 0.564 & 0.59  \\
		\textit{PD\_Coarse20\_SAS} & 0.511 & 0.625 & 0.568 & 0.59  \\\hline 
	\end{tabular}
	\caption{No Previous Delinquency Model results when most important\\
		Macro-Economic features calculated using Coarse selection were included.
		\\ *BA = Balanced Accuracy}
	\label{table:CoarsePDModelResults}
\end{table}

The results from including macro-economic features based on the coarse selection process are compared against the benchmark model (\textit{PD\_Bench\_SAS}) built in Section \ref{sec:benchModels}. \textit{PD\_Coarse5\_SAS} will relate to the model that was trained using the top 5 features from the information gain calculation, \textit{PD\_Coarse10\_SAS} is the top 10 features, \textit{PD\_Coarse15\_SAS} is the top 15 features, \textit{PD\_Coarse20\_SAS} is the top 20 features. The highest results for each performance metric are highlighted in green.

Results are very promising from this experiment,the \textit{PD\_Coarse5\_SAS} and \textit{PD\_Coarse10\_SAS} models outperformed the benchmark model(\textit{PD\_Bench\_SAS}) over every performance measure suggesting it would be valid to include these macro-economic values in the development of a model in the future. 

Although the tests for this experiment are very promising further tests would need to be carried out to evaluate if the inclusion of these binned features in the model is statistically significant. 

\subsubsection{Coarse Selection for No Previous Delinquency Data}

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{NoPreviousDelinq_InformationGain_InteractiveGrouping}
	\caption{Information Value using SAS No Previous Delinquency Features}
	\label{fig:Information Value using SAS No Previous Delinquency Features}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=0.7\textwidth,center]{ExampleInteractiveGroupingNPD}
	\caption{Interactive Grouping Event Rate Chart top 5}
	\label{fig:ExampleInteractiveGroupingNPD}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=0.7\textwidth,center]{NPDCoarseSelectionVariableImportanceInformationGain}
	\caption{Coarse Selection Feature Importance No Previous Delinquency by Information Gain and Gini Statistic}
	\label{fig:NPDCoarseSelectionVariableImportanceInformationGain}
\end{figure}

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{l r r r r}
		\hline
		\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
		\textit{NPD\_Bench\_SAS} & 0.492 & 0.748 & 0.620 & 0.654 \\ \hline
		\textit{NPD\_Coarse5\_SAS}  & 0.492 & 0.738 & 0.615 & 0.664   \\ 
		\textit{NPD\_Coarse10\_SAS} & 0.497 & 0.742 & 0.619 & 0.667  \\ 
		\textit{NPD\_Coarse15\_SAS} & 0.517 & 0.741 & 0.629 & 0.669  \\
		\textit{NPD\_Coarse20\_SAS} & 0.500 & 0.739 & 0.619 & 0.665  \\\hline 
	\end{tabular}
	\caption{No Previous Delinquency Models from Coarse Selection using Information Gain}
	\label{table:CoarseNPDModelResults}
\end{table}

\section{Oversampling}

\begin{table}[H]
	\centering\
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l r r r r}
			\hline
			\textbf{Model} &  \textbf{Dataset} & \textbf{\# Bad} & \textbf{\# Good} & \textbf{\# Observations} & \textbf{Good:Bad} \\
			\hline
			Previous Delinquency & Training Oversample & 1,562 & 1,552 & 3,114 & 50:50\\
			& Test & 245 & 633 & 878 & 72:28\\\hline
			\textbf{Previous Previous Delinquency}     & \textbf{Total} & \textbf{1,807} & \textbf{2,185} & \textbf{3,992} & \textbf{55:45} \\
			\hline
			No Previous Delinquency & Training Oversample & 16,198 & 16,435 & 32,633 & 50:50 \\ 
			& Test & 177 & 7,070 & 7,247 & 97:03 	\\\hline
			\textbf{No Previous Delinquency}     & \textbf{Total} & \textbf{16,375} & \textbf{23,505} & \textbf{39,880} & \textbf{68:32} \\
			\hline
			\textbf{Total } 	&     	     & \textbf{18,182} & \textbf{25,690} & \textbf{43,872} & \textbf{58:42}\\ \hline
		\end{tabular}
	}
	\caption{Breakdown Holdout Training/Test Dataset \\for Oversample Benchmark Models}
	\label{table:benchmark_holdout_oversample_train_test}
\end{table}

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l l r r r r}
			\hline
			\textbf{Model} & \textbf{Dataset} & \textbf{Software} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_OverBench\_R} & Previous Delinquency & R & 0.587 & 0.615 & 0.601 & 0.651   \\ \hline
			\textit{NPD\_OverBench\_R} & No Previous Delinquency & R & 0.559 & 0.720 & 0.640 & 0.67   \\ \hline
		\end{tabular}
	}
	\caption{Benchmark Oversampling Model results for Comparison}
	\label{table:benchmodelOver}
\end{table}

\begin{table}[H]
\centering
\small
		\begin{tabular}{l  r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_OverExper\_R}  & 0.567 & 0.647 & 0.607 & 0.646   \\ \hline
			\textit{NPD\_OverExper\_R} & 0.587 & 0.711 & 0.649 & 0.671   \\ \hline
		\end{tabular}
	\caption{Experiment Oversampling Model Results for Experiment Comparison}
	\label{table:benchmodelOverExper}
\end{table}



\section{Synthetic Sampling}
NonDelinqknnFit

k-Nearest Neighbors 


16408 samples

116 predictor

2 classes: 'N', 'Y' 


Pre-processing: centered (116), scaled (116) 

Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 14768, 14767, 14766, 14767, 14768, 14767, ... 

Resampling results across tuning parameters:

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{NoPreviousDelinquencyExperimentKNN}
	\caption{Repeated 3 Times 10-Fold Cross-Validation Optimal No. of Neighbours for No Previous Delinquency Experiment Data}
	\label{fig:NoPreviousDelinquencyExperimentKNN}
\end{figure}

{\footnotesize
	\begin{longtable}
		{l | l | l | l | l | l | l}
		\hline
		\textbf{k} & \textbf{ROC} & \textbf{Sens} & \textbf{Spec} & \textbf{ROCSD} & \textbf{SensSD} & \textbf{SpecSD} \\ \hline
		5          & 0.474        & 1.000         & 0.000         & 0.023          & 0.000           & 0.000           \\
		7          & 0.469        & 1.000         & 0.000         & 0.024          & 0.000           & 0.000           \\
		9          & 0.467        & 1.000         & 0.000         & 0.030          & 0.000           & 0.000           \\
		11         & 0.462        & 1.000         & 0.000         & 0.030          & 0.000           & 0.000           \\
		13         & 0.468        & 1.000         & 0.000         & 0.027          & 0.000           & 0.000           \\
		15         & 0.471        & 1.000         & 0.000         & 0.024          & 0.000           & 0.000           \\
		17         & 0.479        & 1.000         & 0.000         & 0.031          & 0.000           & 0.000           \\
		19         & 0.485        & 1.000         & 0.000         & 0.042          & 0.000           & 0.000           \\
		21         & 0.501        & 1.000         & 0.000         & 0.048          & 0.000           & 0.000           \\
		23         & 0.520        & 1.000         & 0.000         & 0.049          & 0.000           & 0.000           \\
		25         & 0.532        & 1.000         & 0.000         & 0.045          & 0.000           & 0.000           \\
		27         & 0.535        & 1.000         & 0.000         & 0.041          & 0.000           & 0.000           \\
		29         & 0.547        & 1.000         & 0.000         & 0.033          & 0.000           & 0.000           \\
		31         & 0.548        & 1.000         & 0.000         & 0.034          & 0.000           & 0.000           \\
		33         & 0.550        & 1.000         & 0.000         & 0.032          & 0.000           & 0.000           \\
		35         & 0.541        & 1.000         & 0.000         & 0.043          & 0.000           & 0.000           \\
		37         & 0.475        & 1.000         & 0.000         & 0.056          & 0.000           & 0.000           \\
		39         & 0.452        & 1.000         & 0.000         & 0.040          & 0.000           & 0.000           \\
		41         & 0.447        & 1.000         & 0.000         & 0.033          & 0.000           & 0.000           \\
		43         & 0.447        & 1.000         & 0.000         & 0.035          & 0.000           & 0.000           \\
		45         & 0.444        & 1.000         & 0.000         & 0.041          & 0.000           & 0.000           \\
		47         & 0.454        & 1.000         & 0.000         & 0.052          & 0.000           & 0.000           \\
		49         & 0.476        & 1.000         & 0.000         & 0.067          & 0.000           & 0.000           \\
		51         & 0.481        & 1.000         & 0.000         & 0.071          & 0.000           & 0.000           \\
		53         & 0.501        & 1.000         & 0.000         & 0.073          & 0.000           & 0.000           \\
		55         & 0.511        & 1.000         & 0.000         & 0.070          & 0.000           & 0.000           \\
		57         & 0.509        & 1.000         & 0.000         & 0.069          & 0.000           & 0.000           \\
		59         & 0.508        & 1.000         & 0.000         & 0.065          & 0.000           & 0.000           \\
		61         & 0.517        & 1.000         & 0.000         & 0.066          & 0.000           & 0.000           \\
		63         & 0.525        & 1.000         & 0.000         & 0.064          & 0.000           & 0.000           \\
		65         & 0.536        & 1.000         & 0.000         & 0.053          & 0.000           & 0.000           \\
		67         & 0.536        & 1.000         & 0.000         & 0.052          & 0.000           & 0.000           \\
		69         & 0.545        & 1.000         & 0.000         & 0.051          & 0.000           & 0.000           \\
		71         & 0.552        & 1.000         & 0.000         & 0.047          & 0.000           & 0.000           \\
		73         & 0.552        & 1.000         & 0.000         & 0.044          & 0.000           & 0.000           \\
		\cellcolor{green!25}75         &  \cellcolor{green!25}0.556        &  \cellcolor{green!25}1.000         &  \cellcolor{green!25}0.000         &  \cellcolor{green!25}0.038          &  \cellcolor{green!25}0.000           &  \cellcolor{green!25}0.000           \\
		77         & 0.541        & 1.000         & 0.000         & 0.052          & 0.000           & 0.000           \\
		79         & 0.527        & 1.000         & 0.000         & 0.061          & 0.000           & 0.000           \\
		81         & 0.476        & 1.000         & 0.000         & 0.064          & 0.000           & 0.000           \\
		83         & 0.456        & 1.000         & 0.000         & 0.056          & 0.000           & 0.000          \\ \hline
		\caption{No Previous Delinquency Model Analysis K-NN}
		\label{No Previous Delinquency Model Analysis K-NN}
	\end{longtable}
}

ROC was used to select the optimal model using  the largest value.

The final value used for the model was k = 75. 




DelinqknnFit

k-Nearest Neighbors 

1967 samples

118 predictor

2 classes: 'N', 'Y' 


Pre-processing: centered (118), scaled (118) 

Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 1770, 1771, 1770, 1771, 1770, 1770, ... 

Resampling results across tuning parameters:

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{DelinqencyAnalysisKNN}
	\caption{Repeated 3 Times 10-Fold Cross-Validation Optimal No. of Neighbours for Previous Delinquency Experiment Data}
	\label{fig:DelinqencyAnalysisKNN}
\end{figure}

{\footnotesize
	\begin{longtable}
		{l|l|l|l|l|l|l}
		\hline
		\textbf{k} & \textbf{ROC} & \textbf{Sens} & \textbf{Spec} & \textbf{ROC SD} & \textbf{Sens SD} & \textbf{Spec SD} \\ \hline
		5          & 0.486        & 0.886         & 0.130         & 0.053           & 0.030            & 0.043            \\
		7          & 0.507        & 0.920         & 0.101         & 0.060           & 0.023            & 0.049            \\
		9          & 0.509        & 0.937         & 0.086         & 0.057           & 0.019            & 0.032            \\
		11         & 0.514        & 0.952         & 0.059         & 0.054           & 0.015            & 0.030            \\
		13         & 0.517        & 0.961         & 0.049         & 0.052           & 0.019            & 0.024            \\
		15         & 0.525        & 0.967         & 0.034         & 0.048           & 0.018            & 0.024            \\
		17         & 0.521        & 0.976         & 0.020         & 0.054           & 0.014            & 0.017            \\
		19         & 0.533        & 0.981         & 0.020         & 0.046           & 0.013            & 0.019            \\
		21         & 0.525        & 0.988         & 0.016         & 0.050           & 0.009            & 0.014            \\
		23         & 0.529        & 0.993         & 0.008         & 0.048           & 0.006            & 0.010            \\
		25         & 0.516        & 0.997         & 0.006         & 0.052           & 0.006            & 0.011            \\
		27         & 0.528        & 0.998         & 0.005         & 0.049           & 0.005            & 0.009            \\
		29         & 0.515        & 0.998         & 0.005         & 0.052           & 0.004            & 0.009            \\
		31         & 0.509        & 0.998         & 0.004         & 0.057           & 0.003            & 0.008            \\
		33         & 0.528        & 0.999         & 0.004         & 0.053           & 0.002            & 0.008            \\
		35         & 0.508        & 1.000         & 0.001         & 0.061           & 0.001            & 0.005            \\
		37         & 0.533        & 1.000         & 0.000         & 0.054           & 0.000            & 0.000            \\
		39         & 0.528        & 1.000         & 0.000         & 0.059           & 0.000            & 0.000            \\
		41         & 0.536        & 1.000         & 0.000         & 0.057           & 0.000            & 0.000            \\
		43         & 0.541        & 1.000         & 0.000         & 0.058           & 0.000            & 0.000            \\
		45         & 0.532        & 1.000         & 0.000         & 0.062           & 0.000            & 0.000            \\
		47         & 0.541        & 1.000         & 0.000         & 0.057           & 0.000            & 0.000            \\
		49         & 0.541        & 1.000         & 0.000         & 0.056           & 0.000            & 0.000            \\
		\cellcolor{green!25}51         &  \cellcolor{green!25}0.545        &  \cellcolor{green!25}1.000         &  \cellcolor{green!25}0.000         &  \cellcolor{green!25}0.053           &  \cellcolor{green!25}0.000            &  \cellcolor{green!25}0.000            \\
		53         & 0.539        & 1.000         & 0.000         & 0.056           & 0.000            & 0.000            \\
		55         & 0.539        & 1.000         & 0.000         & 0.057           & 0.000            & 0.000            \\
		57         & 0.535        & 1.000         & 0.000         & 0.056           & 0.000            & 0.000            \\
		59         & 0.545        & 1.000         & 0.000         & 0.049           & 0.000            & 0.000            \\
		61         & 0.539        & 1.000         & 0.000         & 0.052           & 0.000            & 0.000            \\
		63         & 0.540        & 1.000         & 0.000         & 0.052           & 0.000            & 0.000            \\
		65         & 0.545        & 1.000         & 0.000         & 0.045           & 0.000            & 0.000            \\
		67         & 0.534        & 1.000         & 0.000         & 0.052           & 0.000            & 0.000            \\
		69         & 0.540        & 1.000         & 0.000         & 0.047           & 0.000            & 0.000            \\
		71         & 0.543        & 1.000         & 0.000         & 0.047           & 0.000            & 0.000            \\
		73         & 0.532        & 1.000         & 0.000         & 0.053           & 0.000            & 0.000            \\
		75         & 0.541        & 1.000         & 0.000         & 0.044           & 0.000            & 0.000            \\
		77         & 0.541        & 1.000         & 0.000         & 0.042           & 0.000            & 0.000            \\
		79         & 0.538        & 1.000         & 0.000         & 0.044           & 0.000            & 0.000            \\
		81         & 0.529        & 1.000         & 0.000         & 0.050           & 0.000            & 0.000            \\
		83         & 0.537        & 1.000         & 0.000         & 0.048           & 0.000            & 0.000           \\ \hline
		\caption{Delinquency Model Analysis K-NN}
		\label{Delinquency Model Analysis K-NN}
	\end{longtable}
}  

ROC was used to select the optimal model using  the largest value.

The final value used for the model was k = 51.

\begin{table}[H]
	\centering\
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l r r r r}
			\hline
			\textbf{Model} &  \textbf{Dataset} & \textbf{\# Bad} & \textbf{\# Good} & \textbf{\# Observations} & \textbf{Good:Bad} \\
			\hline
			Previous Delinquency & Training Synthetic K51 & 1,449 & 1,932 & 3,381 & 50:50\\
			& Test & 245 & 633 & 878 & 72:28\\\hline
			\textbf{Previous Previous Delinquency}     & \textbf{Total} & \textbf{1,694} & \textbf{2,565} & \textbf{4,259} & \textbf{60:40} \\
			\hline
			No Previous Delinquency & Training Synthetic K75 & 9,480 & 18,012 & 27,492 & 66:34 \\ 
			& Test & 177 & 7,070 & 7,247 & 97:03 	\\\hline
			\textbf{No Previous Delinquency}     & \textbf{Total} & \textbf{9,597} & \textbf{25,032} & \textbf{34,739} & \textbf{72:28} \\
			\hline
			\textbf{Total } 	&     	     & \textbf{11,291} & \textbf{27,597} & \textbf{38,998} & \textbf{71:29}\\ \hline
		\end{tabular}
	}
	\caption{Breakdown Holdout Training/Test Dataset \\for Synthetic Benchmark Models}
	\label{table:benchmark_holdout_Synthetic_train_test}
\end{table}


\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l l r r r r}
			\hline
			\textbf{Model} & \textbf{Dataset} & \textbf{Software} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_SyntheticBench\_R} & Previous Delinquency & R & 0.444 & 0.818 & 0.631 & 0.652   \\ \hline
			\textit{NPD\_SyntheticBench\_R} & No Previous Delinquency & R & 0.610 & 0.677 & 0.643 & 0.67   \\ \hline
		\end{tabular}
	}
	\caption{Benchmark Synthetic Model results for Comparison}
	\label{table:benchmodelSynthetic}
\end{table}

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{l  r r r r}
		\hline
		\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
		\textit{PD\_SyntheticExper\_R}  & 0.444 & 0.803 & 0.624 & 0.650   \\ \hline
		\textit{NPD\_SyntheticExper\_R} & 0.621 & 0.656 & 0.639 & 0.669   \\ \hline
	\end{tabular}
	\caption{Experiment Oversampling Model Results for Experiment Comparison}
	\label{table:benchmodelSyntheticExper}
\end{table}



\section{Conclusion}
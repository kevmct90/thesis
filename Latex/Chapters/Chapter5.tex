% Chapter Template

\chapter{Implementation \& Evaluation} % Main chapter title

\label{Chapter5} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 5. \emph{Experiment Implementation \& Evaluation}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
\section{Introduction}
This chapter will present the implementation of the experiments to evaluate the use of macro-economic features for predicting SME defaults. The predictive capability of customers spending behaviour, personal customer default rates, SME default rates and Census data  will be analysed and discussed.

The experiments in this research are sequential meaning results from one experiment are used in the following experiment. Therefore results will also be discussed and evaluated in this section.

A benchmark predictive model will be built in SAS and R based on historical scorecard features. This will be used to make fair comparisons to the results from the experiments.


\section{Benchmark Models}\label{sec:benchModels}
As mentioned in previous section when building predictive models its is essential to have a baseline or benchmark model to compare your experiments to. Therefore benchmark regression models have been built in R and SAS that will be used to make comparisons to experiments in this chapter. Regression was chosen because of its success in experiments in Section \ref{sec:benchFeature} and its wide use in industry. The models have been trained for both R and SAS using a 70\% stratified sample dataset with 30\% being kept for holdout which will be used for testing. Results may vary from both R and SAS due to varying samples in each application and algorithms will be slightly different but they should relatively close. This will not impact analysis of comparing experiments as experiments in R will be compared to the benchmark from R and likewise for comparisons in SAS. The AUC will the performance measure of choice for evaluating the well the model fits over all possible thresholds. As the AUC does not give us the accuracy of the model a specific threshold we will also use the recall, specificity and balanced accuracy(BA). The threshold used is based on fine tuning of the parameters testing using a validation dataset in Section \ref{sec:benchFeature}. The breakdown of the training and test for the benchmark model datasets and their target class distribution can be shown in Table \ref{table:benchmark_holdout_train_test}.

\begin{table}[H]
	\centering\
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l r r r r}
			\hline
			\textbf{Model} &  \textbf{Dataset} & \textbf{\# Bad} & \textbf{\# Good} & \textbf{\# Observations} & \textbf{Good:Bad} \\
			\hline
			Previous Delinquency & Training       & 483 & 1,565 & 2,048 & 76:24\\
			          & Test & 245 & 633 & 878 & 72:28\\\hline
			\textbf{Previous Previous Delinquency}     & \textbf{Total} & \textbf{728} & \textbf{2,198} & \textbf{2,926} & \textbf{75:25} \\
			\hline
			No Previous Delinquency & Training & 474 & 16,435 & 16,909 & 97:03 \\ 
			          & Test & 177 & 7,070 & 7,247 & 97:03 	\\\hline
			\textbf{No Previous Delinquency}     & \textbf{Total} & \textbf{651} & \textbf{23,505} & \textbf{24,156} & \textbf{97:03} \\
			\hline
			\textbf{Total } 	&     	     & \textbf{1,379} & \textbf{25,703} & \textbf{27,082} & \textbf{95:05}\\ \hline
		\end{tabular}
	}
	\caption{Breakdown Holdout Training/Test Dataset \\for Benchmark Models}
	\label{table:benchmark_holdout_train_test}
\end{table}

The threshold used for performance measuring is based on fine tuning of the parameters testing using a validation dataset in Section \ref{sec:benchFeature}. The results from the benchmark models can be found in Table \ref{table:benchmodel} below.

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{\footnotesize
		\begin{tabular}{l l l r r r r}
			\hline
			\textbf{Model} & \textbf{Dataset} & \textbf{Software} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_Bench\_R} & Previous Delinquency & R & 0.54 & 0.70 & 0.62 & 0.654   \\ 
			\textit{PD\_Bench\_SAS} & Previous Delinquency & SAS & 0.53 & 0.62 & 0.57 & 0.62   \\ \hline
			\textit{NPD\_Bench\_R} & No Previous Delinquency & R & 0.53 & 0.74 & 0.63 & 0.65   \\ 
			\textit{NPD\_Bench\_SAS} & No Previous Delinquency & SAS & 0.49 & 0.74 & 0.62 & 0.65   \\ \hline
		\end{tabular}
	}
	\caption{Benchmark Model Results for Experiment Comparison}
	\label{table:benchmodel}
\end{table}

Models in this this section will be aliased for ease of reading, for example the benchmark models will be referred to as \textit{PD\_Bench\_R}, \textit{PD\_Bench\_SAS}, \textit{NPD\_Bench\_R} and \textit{NPD\_Bench\_SAS} which can be seen in Table \ref{table:benchmodel} above. The results found here are consistent with the evaluations completed in Chapter \ref{Chapter4} which guarantees we have good benchmarks to compare the results in the experiment in this chapter to.


\section{Correlation Analysis}
Correlation matrix is a very simple and powerful way of analysing the relationship of predictive features with each other and the target features. Including highly correlated predictive features has the potential to throw off or fool your predictive model potentially causing misleading results. The Pearson correlation coefficient is a common measure used to test your data to check this relationship and will be deployed in this experiment. The correlation tests are ran separately on each category of features created as part of this experiment e.g. \textit{CSO Features by ED \& LA}, \textit{SME Default Trends by ED \& LA}, \textit{Homeloan and Personal Loan Default Trends by ED \& LA}, \textit{Transactions Behaviour by ED \& LA}, and \textit{Binned SME Defaults Rates by ED and LA}. Fig. \ref{fig:unbal_corr_analysis} shows a subset of the results demonstrating correlation scores between the experiment features categories with a full breakdown of the results available in Appendix \ref{AppendixB} where a correlation score coloured red represents a very strong positive correlation between features and blue a very low negative correlation.

\begin{figure}[H]
	\centering
 	\begin{subfigure}[b]{0.32\textwidth}
 		\captionsetup{font=scriptsize}
 		\includegraphics[width=\textwidth,height=2.75cm]{CSO_Correlation_Analysis}
 		\caption{CSO Features by ED \& LA\\}
 		\label{fig:CSOCorrelation}
 	\end{subfigure}
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{SME_Arrears_Trends_Correlation_Analysis_Subset}
		\caption{SME Default Trends \\by ED \& LA}\label{fig:smeArrearsCorrelation}
	\end{subfigure} 
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Personal_Arrears_Ratio}
		\caption{Homeloan and Personal Loan Default Trends by ED \& LA}
		\label{fig:personalArrearsCorrelation}
	\end{subfigure} 
	\medskip
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Visa_Debit_Correlation_Analysis_Subset}
		\caption{Transactions Behaviour \\by ED \& LA }\label{fig:transVisaCorrelation}
	\end{subfigure} ~\quad
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Grouped_Features_Correlation_Analysis_Subset}
		\caption{Binned SME Defaults Rates \\by ED and LA\\}
		\label{fig:groupedFeaturesCorrelation}
	\end{subfigure}
	\caption{Correlation Analysis}
	\label{fig:unbal_corr_analysis}
\end{figure}

There is a high level of correlation between among many of the variables. It was decided that any features that had a correlation score of 0.80 would be candidate features for removal. For features that were this highly correlated the feature scoring the lowest bivariate correlation to the target feature was removed, ensuring the variable which had the strongest relationship with the target class was prioritised and kept for further predictions. The a subset of the results after this feature reduction process can be found in Fig. \ref{unbal_corr_analysis_filtered} with a full set of results available in Appendix \ref{AppendixC}. 

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{CSO_Correlation_Analysis}
		\caption{CSO Features by ED \& LA\\}
		\label{fig:CSOCorrelation}
	\end{subfigure}
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{SMETrendsCorrSub}
		\caption{SME Default Trends \\by ED \& LA}\label{fig:SMETrendsCorrSub}
	\end{subfigure} 
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{PersonalTrendFull}
		\caption{Homeloan and Personal Loan Default Trends by ED \& LA}
		\label{fig:PersonalTrendFull}
	\end{subfigure} 
	\medskip
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{TransactionCorrSub}
		\caption{Transactions Behaviour \\by ED \& LA }\label{fig:TransactionCorrSub}
	\end{subfigure} ~\quad
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{GroupedCorrSub}
		\caption{Binned SME Defaults Rates \\by ED and LA\\}
		\label{fig:GroupedCorrSub}
	\end{subfigure}
	\caption{Correlation Analysis after highly correlated features have been removed}
	\label{fig:unbal_corr_analysis_filtered}
\end{figure}

We then analyse the variables that are most correlated with the target to see if included in the prediction model how well it performs, results from this analysis are demonstrated in Fig. \ref{fig:Correlation Analysis} below.

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{CorrelationChart}
	\caption{Most correlated features with target variable}
	\label{fig:Correlation Analysis}
\end{figure}

Table \ref{table:CorrModelResults} below shows the results from including the top 5, 10, 15, 20 correlated features after the correlation analysis as per the Table \ref{table:CorrModelResults}. 

\begin{table}[H]
\centering
\small
		\begin{tabular}{l r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_Cor5\_R}  & 0.534 & 0.685 & 0.610 & 0.654   \\ 
			\textit{PD\_Cor10\_R} & 0.556 & 0.679 & 0.618 & 0.658  \\ 
			\textit{PD\_Cor15\_R} & 0.594 & 0.690 & 0.643 & 0.665  \\
			\textit{PD\_Cor20\_R} & 0.561 & 0.698 & 0.630 & 0.665  \\\hline 
			
			\textit{NPD\_Cor5\_R}  & 0.525 & 0.743 & 0.634 & 0.671   \\ 
			\textit{NPD\_Cor10\_R} & 0.555 & 0.725 & 0.640 & 0.677  \\ 
			\textit{NPD\_Cor15\_R} & 0.538 & 0.723 & 0.630 & 0.680  \\
			\textit{NPD\_Cor20\_R} & 0.549 & 0.731 & 0.640 & 0.676  \\\hline 
		\end{tabular}
	\caption{Models from Correlation Feature Selection}
	\label{table:CorrModelResults}
\end{table}

For each model result the AUC will be used to measure the overall accuracy of the model while Recall, Specificity, Balanced Accuracy will be recorded to evaluate how the model performs at specified threshold. These results will be evaluated against the benchmark results in a later section of the chapter.


\section{Feature Selection}
As mentioned in the research literature in Section \ref{sec2:featureSection} feature selection is important when building a predictive model for a reasons such as reducing the complexity of the model, mitigating the risk of over-fitting, overhead involved with having to understand and maintain a larger number of features, model training and computation time and when you need evaluate/explain your results. In summary simpler in the majority of cases is better.

Therefore a number of feature selection process will be experimented with in this section to try and identify the features that are of key importance, reducing the complexity of the model and identifying the important features. The two process that will be used are \textit{Information Gain Feature Importance} and \textit{Random Forest Feature Importance}

The feature selection process of this experiment was only carried out on the training partitions of the dataset.

\subsection{Information Gain Feature Importance}
Information gain is an approach that utilises measures commonly seen when a decision tree model is being trained (See Section \ref{decTrees}). It calculates and ranks features using entropy and information gain. For each experiment the existing scorecard features and macro-economic features as part of this experiment were analysed. Since we are only interested in the identifying the importance of macro-economic features as part of this research the existing features were stripped out of the result as we cannot tamper with the benchmark model dataset as this could lead to misleading results. Due to the risks previously discussed with having too many features in your training dataset only the top 20 features will be included in models to be trained along with the existing scorecard features as part of this experiment.

\subsubsection{Information Gain for Previous Delinquency Data} \label{IGPDExper}
Addressing the \textit{Previous Delinquency} dataset the information gain was calculated for each of the existing scorecard features and macro-economic features. Details of the feature importance can be seen in Fig. \ref{fig:DelinqInformationGainAnalysis}

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{DelinqInformationGainAnalysis}
	\caption{Top 20 Macro-Economic Feature calculated by \\ Information Gain on Previous Delinquency Dataset}
	\label{fig:DelinqInformationGainAnalysis}
\end{figure}

As can be seen in Fig. \ref{fig:DelinqInformationGainAnalysis} the results from this test are not very promising. The information gain is very small for features which suggests the features were not any better at explaining the target feature than the existing scorecard features. 

The features that show strongest performance \textit{ED\_LOAN}, \textit{ED\_HOME} as based on default rates of personal loan and homeloan customers at electoral division. This intuitively could makes sense i.e. if people in an electoral division are struggling with their loan and mortgage repayments they are less likely to spend money in businesses in that area. \textit{ED\_LOWER\_THAN\_UPPER\_SECONDARY}, \textit{ED\_UNEMPLOYMENT} and \textit{ED\_NON\_MANUALOCCUPATION} relates to features created in the census data to with low levels of education, high unemployment rate which again intuitively at least make sense. If there are people in an area with low levels of education and therefore cant get work they're less likely to spend money on businesses in that area.

Despite the low information gain of all macro economic feature in the results above we re-train and test the model including the most important features from the information gain calculation. Separate models will be trained using the top 5, 10, 15 and 20 features from the information gain calculation. Table \ref{table:InfoGainPDModelResults} details the results for the re-trained model on the test data using the features selected as part of the information gain calculation.

\begin{table}[H]
\centering
\small
		\begin{tabular}{l r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA*} & \textbf{AUC}  \\ \hline
			\textit{PD\_Bench\_R} & 0.540 & 0.700 & 0.620 & \cellcolor{green!25}0.654 \\ \hline
			\textit{PD\_IG5\_R} & 0.540 & \cellcolor{green!25}0.715 & 0.627 & 0.652   \\ 
			\textit{PD\_IG10\_R} & \cellcolor{green!25}0.548 & 0.693 & 0.621 & 0.649  \\ 
			\textit{PD\_IG15\_R} & 0.536 & 0.690 & 0.613 & 0.65  \\
			\textit{PD\_IG20\_R} & 0.544 & 0.711 & \cellcolor{green!25}0.628 & 0.651 \\\hline 
		\end{tabular}
	\caption{Previous Delinquency Model results when most important \\Macro-Economic features calculated using Information Gain were included in training.\\
		*BA = Balanced Accuracy}
	\label{table:InfoGainPDModelResults}
\end{table}

The results from including macro-economic features based on the information gain feature importance are compared against the benchmark model (\textit{PD\_Bench\_R})built in Section \ref{sec:benchModels}. \textit{PD\_IG5\_R} will relate to the model that was trained using the top 5 features from the information gain calculation, \textit{PD\_IG10\_R} is the top 10 features, \textit{PD\_IG15\_R} is the top 15 features, \textit{PD\_IG20\_R} is the top 20 features.The highest results for each performance metric are highlighted in green.

None of the models trained in this experiment performed better under the AUC which identifies the best model accuracy of the model over all possible thresholds. The \textit{PD\_IG5\_R}, \textit{PD\_IG20\_R} models have a larger specificity than the benchmark meaning the model was able to identify a larger proportion of the negative cases correctly. \textit{PD\_IG10\_R} and \textit{PD\_IG20\_R} both returned higher balanced accuracy and recall. Higher recall means both models predicted higher percentage of the positive class correctly. Although this is an improvement on the benchmark models the results are not markedly better and would need further investigation to test for statistical significance.

\subsubsection{Information Gain for No Previous Delinquency Data}\label{IGNPDExper}
Addressing the \textit{No Previous Delinquency} dataset the information gain was calculated for each of the existing scorecard features and macro-economic features. Details of the feature importance can be seen in Fig. \ref{fig:NoDelinqInformationGainAnalysis}

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{NoDelinqInformationGainAnalysis}
	\caption{Top 20 Macro-Economic Feature calculated by \\ Information Gain on No Previous Delinquency Dataset}
	\label{fig:NoDelinqInformationGainAnalysis}
\end{figure}

It can be seen in Fig. \ref{fig:NoDelinqInformationGainAnalysis} the results from this test are not very promising as with the previous experiment. The information gain is very small for features which suggests the features were not any better at explaining the target feature than the existing scorecard features. 

The features that show strongest performance as based on SME default rates in an electoral division (See \ref{SMEDefaultBehaviourDataset}). The features that show strongest performance \textit{ED PERCENT 30 06 2014}, \textit{ED CNT 1 30 06 2014} as based on the default rate of SME customers and the number of SME customers in default at an electoral division. \textit{DIFF 12 2013} to \textit{ED DIFF 06 2012 ED} are based on the percentage change of default rates. Again these intuitively for predicting either the negative of positive class. If defaulting is trending up in area they could be indicative of further defaulters, likewise if default rate is or going down consumer spend must be good in these areas and there is smaller risk of default is the future

Again despite the low information gain of all macro economic feature in the results above we re-train and test the model including the most important features from the information gain calculation. Separate models will be trained using the top 5, 10, 15 and 20 features from the information gain calculation. Table \ref{table:InfoGainNPDModelResults} details the results for the re-trained model on the test data using the features selected as part of the information gain calculation.


\begin{table}[H]
\centering
\small
		\begin{tabular}{l r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA*} & \textbf{AUC}  \\ \hline
			\textit{NPD\_Bench\_R} & 0.530 & \cellcolor{green!25}0.740 & 0.630 & 0.650   \\ \hline
			\textit{NPD\_IG5\_R} & \cellcolor{green!25}0.542 & 0.736 & \cellcolor{green!25}0.639 & \cellcolor{green!25}0.667   \\ 
			\textit{NPD\_IG10\_R} & 0.536 & 0.736 & 0.636 & 0.667  \\ 
			\textit{NPD\_IG15\_R} & 0.520 & 0.732 & 0.626 & 0.663 \\
			\textit{NPD\_IG20\_R} &  0.508 & 0.730 & 0.619 & 0.665  \\\hline 
		\end{tabular}
	\caption{No Previous Delinquency Model results when most important \\Macro-Economic features calculated using Information Gain were included in training.\\
		*BA = Balanced Accuracy}
	\label{table:InfoGainNPDModelResults}
\end{table}

The results from including macro-economic features based on the information gain feature importance are compared against the benchmark model (\textit{PD\_Bench\_R})built in Section \ref{sec:benchModels}. \textit{NPD\_IG5\_R} will relate to the model that was trained using the top 5 features from the information gain calculation, \textit{NPD\_IG10\_R} is the top 10 features, \textit{NPD\_IG15\_R} is the top 15 features, \textit{NPD\_IG20\_R} is the top 20 features. The highest results for each performance metric are highlighted in green.

All four models (\textit{NPD\_IG5\_R}, \textit{NPD\_IG10\_R}, \textit{NPD\_IG15\_R}, \textit{NPD\_IG20\_R}) outperformed the benchmark model in terms of the AUC which identifies the best model accuracy of the model over all possible thresholds. Of these \textit{NPD\_IG5\_R} performed the strongest by scoring a highest recall and balanced accuracy of models compared. This means it was identifying it a predicted higher percentage of the positive class correctly than the benchmark. Although this is an improvement on the benchmark models the results are not markedly better and would need further investigation to test for statistical significance.

\subsection{Random Forest Feature Importance}
A random forest is a very common and popular method of building a predictive modelling. It is an extension of the previously discussed decision tree (See Section \ref{decTrees}). The approach is to create large number of decision trees and then combine them together to make a classification, hence why its called a forest. For each decision tree random subsets of the full training set for each decision tree are used, hence random. Hence this is why it is called a random forest. It is also widely in the process of feature selection every build $n$ number of trees in your forest and evaluate how much each feature improves the classification over the entire forest. 

For both the \textit{Previous Delinquency} and \textit{No Previous Delinquency} experiments in this section 1000 trees will be created to evaluate the importance of all the features. As with the previous experiment since we are only
interested in the identifying the importance of macro-economic features as part of this
research the existing features were stripped out of the results as tampering with the benchmark model dataset as this could lead to misleading results. Due to the risks previously discussed
with having too many features in your training dataset only the top 20 features will be
included in models to be trained along with the existing scorecard features as part of this experiment.


\subsubsection{Feature Importance for Previous Delinquency Data using Random Forests}
Addressing the size of the Previous Delinquency dataset random forest feature importance was calculated for
each of the existing scorecard features and macro-economic features. Details of the feature importance can be seen in Fig. \ref{fig:DelinqRandomForestsAnalysis} below

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{DelinqRandomForestsAnalysis}
	\caption{Top 20 Macro-Economic Feature calculated by \\
		Random Forest Feature Importance on Previous Delinquency Dataset}
	\label{fig:DelinqRandomForestsAnalysis}
\end{figure}

It can be seen in Fig. \ref{fig:DelinqRandomForestsAnalysis} that features associated with discretionary and non discretionary (See Table \ref{discretionarySpend}) perform strongly in this analysis as 17 of the top 20 features are represented by this dataset. It is worth noting that all of there features are at an electoral division level opposed local authority which signify there has been some shift in customer discretionary and non discretionary at the geographic level that is useful for predicting SME defaults or non-defaults. As with the previous experiment calculating information gain  (See Section \ref{IGNPDExper}) the SME default rates at an electoral division also included in the top 20 most important features.

Using these results separate models will be trained using the top 5, 10, 15 and 20 features from
the random forest feature importance algorithm. Table \ref{table:RFPDModelResults} details the results for the re-trained model
on the test data using the features selected as part of the random forest feature ranking

\begin{table}[H]
\centering
\small
		\begin{tabular}{l r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_Bench\_R} & 0.540 & 0.700 & 0.620 & 0.654 \\ \hline
			\textit{PD\_RF5\_R} & 0.548 & 0.692 & 0.620 & \cellcolor{green!25}0.662   \\ 
			\textit{PD\_RF10\_R} & \cellcolor{green!25}0.556 & \cellcolor{green!25}0.703 & \cellcolor{green!25}0.630 & 0.655  \\ 
			\textit{PD\_RF15\_R} & 0.548 & 0.698 & 0.623 & 0.654  \\
			\textit{PD\_RF20\_R} & 0.535 & 0.698 & 0.617 & 0.651  \\\hline 
		\end{tabular}

	\caption{Previous Delinquency Model results when most important\\
Macro-Economic features calculated using Random Forest feature \\selection were included in training.
\\*BA = Balanced Accuracy}
	\label{table:RFPDModelResults}
\end{table}

The results from including macro-economic features based on the random forest feature selection are compared against the benchmark model (\textit{PD\_Bench\_R}) built in Section \ref{sec:benchModels}. \textit{PD\_RF5\_R} will relate to the model that was trained using the top 5 features from the information gain calculation, \textit{PD\_RF10\_R} is the top 10 features, \textit{PD\_RF15\_R} is the top 15 features, \textit{PD\_RF20\_R} is the top 20 features. The highest results for each performance metric are highlighted in green.

Results are promising from this experiment, the benchmark model did not outperform the models ran as part of this experiment for any performance measure. \textit{PD\_RF10\_R} demonstrated  very promising results returning a better result for every performance measure compared to the benchmark model. The only result it was not optimal in was the AUC which scored highest in the \textit{PD\_RF20\_R} model. Although the \textit{PD\_RF10\_R} is outperforming the benchmark on all measures the results are not markedly better and would need further investigation to test for statistical significance.

\subsubsection{Random Forest No Delinquency Model Existing \& Experimental Features}

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{NoDelinqRandomForestsAnalysis}
	\caption{Macro-Economic Feature Importance using Random Forests}
	\label{fig:NoDelinqRandomForestsAnalysis}
\end{figure}


\begin{table}[H]
\centering
\small
		\begin{tabular}{l  r r r r}
			\hline
			\textbf{Model}  & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{NPD\_Bench\_R} & 0.530 & 0.740 & 0.630 & 0.650   \\ \hline
			\textit{NPD\_RF5\_R}  & 0.534 & 0.685 & 0.610 & 0.654   \\ 
			\textit{NPD\_RF10\_R} & 0.556 & 0.679 & 0.618 & 0.658  \\ 
			\textit{NPD\_RF15\_R} & 0.594 & 0.690 & 0.643 & 0.665  \\
			\textit{NPD\_RF20\_R} & 0.561 & 0.698 & 0.630 & 0.665  \\\hline 
		\end{tabular}

	\caption{Models from Random Forest Feature Selection for No Previous Delinquency}
	\label{table:RFNPDModelResults}
\end{table}


\section{Interactive Grouping}

\subsubsection{Previous Delinquency}
\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{PreviousDelinq_InformationGain_InteractiveGrouping}
	\caption{Information Value using SAS Previous Delinquency Features}
	\label{fig:Information Value using SAS Previous Delinquency Features}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=0.7\textwidth,center]{ExampleInteractiveGrouping}
	\caption{Interactive Grouping Diff Percent 06 2012 ED}
	\label{fig:Interactive Grouping Diff Percent 06 2012 ED}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=0.7\textwidth,center]{PDCoarseSelectionVariableImportanceInformationGain}
	\caption{Coarse Selection Feature Importance Previous Delinquency by Information Gain and Gini Statistic}
	\label{fig:PDCoarseSelectionVariableImportanceInformationGain}
\end{figure}

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{l r r r r}
		\hline
		\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
		\textit{PD\_Coarse5\_SAS}  & 0.543 & 0.645 & 0.694 & 0.627   \\ 
		\textit{PD\_Coarse10\_SAS} & 0.552 & 0.618 & 0.585 & 0.619  \\ 
		\textit{PD\_Coarse15\_SAS} & 0.511 & 0.618 & 0.564 & 0.59  \\
		\textit{PD\_Coarse20\_SAS} & 0.511 & 0.625 & 0.568 & 0.59  \\\hline 
	\end{tabular}
	\caption{Previous Delinquency Models from Coarse Selection using Information Gain}
	\label{table:CoarsePDModelResults}
\end{table}


\subsubsection{No Previous Delinquency}

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{NoPreviousDelinq_InformationGain_InteractiveGrouping}
	\caption{Information Value using SAS No Previous Delinquency Features}
	\label{fig:Information Value using SAS No Previous Delinquency Features}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=0.7\textwidth,center]{ExampleInteractiveGroupingNPD}
	\caption{Interactive Grouping Event Rate Chart top 5}
	\label{fig:ExampleInteractiveGroupingNPD}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=0.7\textwidth,center]{NPDCoarseSelectionVariableImportanceInformationGain}
	\caption{Coarse Selection Feature Importance No Previous Delinquency by Information Gain and Gini Statistic}
	\label{fig:NPDCoarseSelectionVariableImportanceInformationGain}
\end{figure}

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{l r r r r}
		\hline
		\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
		\textit{NPD\_Coarse5\_SAS}  & 0.492 & 0.738 & 0.615 & 0.664   \\ 
		\textit{NPD\_Coarse10\_SAS} & 0.497 & 0.742 & 0.619 & 0.667  \\ 
		\textit{NPD\_Coarse15\_SAS} & 0.517 & 0.741 & 0.629 & 0.669  \\
		\textit{NPD\_Coarse20\_SAS} & 0.50 & 0.739 & 0.619 & 0.665  \\\hline 
	\end{tabular}
	\caption{No Previous Delinquency Models from Coarse Selection using Information Gain}
	\label{table:CoarseNPDModelResults}
\end{table}

\section{Oversampling}

\begin{table}[H]
	\centering\
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l r r r r}
			\hline
			\textbf{Model} &  \textbf{Dataset} & \textbf{\# Bad} & \textbf{\# Good} & \textbf{\# Observations} & \textbf{Good:Bad} \\
			\hline
			Previous Delinquency & Training Oversample & 1,562 & 1,552 & 3,114 & 50:50\\
			& Test & 245 & 633 & 878 & 72:28\\\hline
			\textbf{Previous Previous Delinquency}     & \textbf{Total} & \textbf{1,807} & \textbf{2,185} & \textbf{3,992} & \textbf{55:45} \\
			\hline
			No Previous Delinquency & Training Oversample & 16,198 & 16,435 & 32,633 & 50:50 \\ 
			& Test & 177 & 7,070 & 7,247 & 97:03 	\\\hline
			\textbf{No Previous Delinquency}     & \textbf{Total} & \textbf{16,375} & \textbf{23,505} & \textbf{39,880} & \textbf{68:32} \\
			\hline
			\textbf{Total } 	&     	     & \textbf{18,182} & \textbf{25,690} & \textbf{43,872} & \textbf{58:42}\\ \hline
		\end{tabular}
	}
	\caption{Breakdown Holdout Training/Test Dataset \\for Oversample Benchmark Models}
	\label{table:benchmark_holdout_oversample_train_test}
\end{table}

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l l r r r r}
			\hline
			\textbf{Model} & \textbf{Dataset} & \textbf{Software} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_OverBench\_R} & Previous Delinquency & R & 0.587 & 0.615 & 0.601 & 0.651   \\ \hline
			\textit{NPD\_OverBench\_R} & No Previous Delinquency & R & 0.559 & 0.720 & 0.640 & 0.67   \\ \hline
		\end{tabular}
	}
	\caption{Benchmark Oversampling Model results for Comparison}
	\label{table:benchmodelOver}
\end{table}

\begin{table}[H]
\centering
\small
		\begin{tabular}{l  r r r r}
			\hline
			\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_OverExper\_R}  & 0.567 & 0.647 & 0.607 & 0.646   \\ \hline
			\textit{NPD\_OverExper\_R} & 0.587 & 0.711 & 0.649 & 0.671   \\ \hline
		\end{tabular}
	\caption{Experiment Oversampling Model Results for Experiment Comparison}
	\label{table:benchmodelOverExper}
\end{table}



\section{Synthetic Sampling}
NonDelinqknnFit

k-Nearest Neighbors 


16408 samples

116 predictor

2 classes: 'N', 'Y' 


Pre-processing: centered (116), scaled (116) 

Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 14768, 14767, 14766, 14767, 14768, 14767, ... 

Resampling results across tuning parameters:

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{NoPreviousDelinquencyExperimentKNN}
	\caption{Repeated 3 Times 10-Fold Cross-Validation Optimal No. of Neighbours for No Previous Delinquency Experiment Data}
	\label{fig:NoPreviousDelinquencyExperimentKNN}
\end{figure}

{\footnotesize
	\begin{longtable}
		{l | l | l | l | l | l | l}
		\hline
		\textbf{k} & \textbf{ROC} & \textbf{Sens} & \textbf{Spec} & \textbf{ROCSD} & \textbf{SensSD} & \textbf{SpecSD} \\ \hline
		5          & 0.474        & 1.000         & 0.000         & 0.023          & 0.000           & 0.000           \\
		7          & 0.469        & 1.000         & 0.000         & 0.024          & 0.000           & 0.000           \\
		9          & 0.467        & 1.000         & 0.000         & 0.030          & 0.000           & 0.000           \\
		11         & 0.462        & 1.000         & 0.000         & 0.030          & 0.000           & 0.000           \\
		13         & 0.468        & 1.000         & 0.000         & 0.027          & 0.000           & 0.000           \\
		15         & 0.471        & 1.000         & 0.000         & 0.024          & 0.000           & 0.000           \\
		17         & 0.479        & 1.000         & 0.000         & 0.031          & 0.000           & 0.000           \\
		19         & 0.485        & 1.000         & 0.000         & 0.042          & 0.000           & 0.000           \\
		21         & 0.501        & 1.000         & 0.000         & 0.048          & 0.000           & 0.000           \\
		23         & 0.520        & 1.000         & 0.000         & 0.049          & 0.000           & 0.000           \\
		25         & 0.532        & 1.000         & 0.000         & 0.045          & 0.000           & 0.000           \\
		27         & 0.535        & 1.000         & 0.000         & 0.041          & 0.000           & 0.000           \\
		29         & 0.547        & 1.000         & 0.000         & 0.033          & 0.000           & 0.000           \\
		31         & 0.548        & 1.000         & 0.000         & 0.034          & 0.000           & 0.000           \\
		33         & 0.550        & 1.000         & 0.000         & 0.032          & 0.000           & 0.000           \\
		35         & 0.541        & 1.000         & 0.000         & 0.043          & 0.000           & 0.000           \\
		37         & 0.475        & 1.000         & 0.000         & 0.056          & 0.000           & 0.000           \\
		39         & 0.452        & 1.000         & 0.000         & 0.040          & 0.000           & 0.000           \\
		41         & 0.447        & 1.000         & 0.000         & 0.033          & 0.000           & 0.000           \\
		43         & 0.447        & 1.000         & 0.000         & 0.035          & 0.000           & 0.000           \\
		45         & 0.444        & 1.000         & 0.000         & 0.041          & 0.000           & 0.000           \\
		47         & 0.454        & 1.000         & 0.000         & 0.052          & 0.000           & 0.000           \\
		49         & 0.476        & 1.000         & 0.000         & 0.067          & 0.000           & 0.000           \\
		51         & 0.481        & 1.000         & 0.000         & 0.071          & 0.000           & 0.000           \\
		53         & 0.501        & 1.000         & 0.000         & 0.073          & 0.000           & 0.000           \\
		55         & 0.511        & 1.000         & 0.000         & 0.070          & 0.000           & 0.000           \\
		57         & 0.509        & 1.000         & 0.000         & 0.069          & 0.000           & 0.000           \\
		59         & 0.508        & 1.000         & 0.000         & 0.065          & 0.000           & 0.000           \\
		61         & 0.517        & 1.000         & 0.000         & 0.066          & 0.000           & 0.000           \\
		63         & 0.525        & 1.000         & 0.000         & 0.064          & 0.000           & 0.000           \\
		65         & 0.536        & 1.000         & 0.000         & 0.053          & 0.000           & 0.000           \\
		67         & 0.536        & 1.000         & 0.000         & 0.052          & 0.000           & 0.000           \\
		69         & 0.545        & 1.000         & 0.000         & 0.051          & 0.000           & 0.000           \\
		71         & 0.552        & 1.000         & 0.000         & 0.047          & 0.000           & 0.000           \\
		73         & 0.552        & 1.000         & 0.000         & 0.044          & 0.000           & 0.000           \\
		\cellcolor{green!25}75         &  \cellcolor{green!25}0.556        &  \cellcolor{green!25}1.000         &  \cellcolor{green!25}0.000         &  \cellcolor{green!25}0.038          &  \cellcolor{green!25}0.000           &  \cellcolor{green!25}0.000           \\
		77         & 0.541        & 1.000         & 0.000         & 0.052          & 0.000           & 0.000           \\
		79         & 0.527        & 1.000         & 0.000         & 0.061          & 0.000           & 0.000           \\
		81         & 0.476        & 1.000         & 0.000         & 0.064          & 0.000           & 0.000           \\
		83         & 0.456        & 1.000         & 0.000         & 0.056          & 0.000           & 0.000          \\ \hline
		\caption{No Previous Delinquency Model Analysis K-NN}
		\label{No Previous Delinquency Model Analysis K-NN}
	\end{longtable}
}

ROC was used to select the optimal model using  the largest value.

The final value used for the model was k = 75. 




DelinqknnFit

k-Nearest Neighbors 

1967 samples

118 predictor

2 classes: 'N', 'Y' 


Pre-processing: centered (118), scaled (118) 

Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 1770, 1771, 1770, 1771, 1770, 1770, ... 

Resampling results across tuning parameters:

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{DelinqencyAnalysisKNN}
	\caption{Repeated 3 Times 10-Fold Cross-Validation Optimal No. of Neighbours for Previous Delinquency Experiment Data}
	\label{fig:DelinqencyAnalysisKNN}
\end{figure}

{\footnotesize
	\begin{longtable}
		{l|l|l|l|l|l|l}
		\hline
		\textbf{k} & \textbf{ROC} & \textbf{Sens} & \textbf{Spec} & \textbf{ROC SD} & \textbf{Sens SD} & \textbf{Spec SD} \\ \hline
		5          & 0.486        & 0.886         & 0.130         & 0.053           & 0.030            & 0.043            \\
		7          & 0.507        & 0.920         & 0.101         & 0.060           & 0.023            & 0.049            \\
		9          & 0.509        & 0.937         & 0.086         & 0.057           & 0.019            & 0.032            \\
		11         & 0.514        & 0.952         & 0.059         & 0.054           & 0.015            & 0.030            \\
		13         & 0.517        & 0.961         & 0.049         & 0.052           & 0.019            & 0.024            \\
		15         & 0.525        & 0.967         & 0.034         & 0.048           & 0.018            & 0.024            \\
		17         & 0.521        & 0.976         & 0.020         & 0.054           & 0.014            & 0.017            \\
		19         & 0.533        & 0.981         & 0.020         & 0.046           & 0.013            & 0.019            \\
		21         & 0.525        & 0.988         & 0.016         & 0.050           & 0.009            & 0.014            \\
		23         & 0.529        & 0.993         & 0.008         & 0.048           & 0.006            & 0.010            \\
		25         & 0.516        & 0.997         & 0.006         & 0.052           & 0.006            & 0.011            \\
		27         & 0.528        & 0.998         & 0.005         & 0.049           & 0.005            & 0.009            \\
		29         & 0.515        & 0.998         & 0.005         & 0.052           & 0.004            & 0.009            \\
		31         & 0.509        & 0.998         & 0.004         & 0.057           & 0.003            & 0.008            \\
		33         & 0.528        & 0.999         & 0.004         & 0.053           & 0.002            & 0.008            \\
		35         & 0.508        & 1.000         & 0.001         & 0.061           & 0.001            & 0.005            \\
		37         & 0.533        & 1.000         & 0.000         & 0.054           & 0.000            & 0.000            \\
		39         & 0.528        & 1.000         & 0.000         & 0.059           & 0.000            & 0.000            \\
		41         & 0.536        & 1.000         & 0.000         & 0.057           & 0.000            & 0.000            \\
		43         & 0.541        & 1.000         & 0.000         & 0.058           & 0.000            & 0.000            \\
		45         & 0.532        & 1.000         & 0.000         & 0.062           & 0.000            & 0.000            \\
		47         & 0.541        & 1.000         & 0.000         & 0.057           & 0.000            & 0.000            \\
		49         & 0.541        & 1.000         & 0.000         & 0.056           & 0.000            & 0.000            \\
		\cellcolor{green!25}51         &  \cellcolor{green!25}0.545        &  \cellcolor{green!25}1.000         &  \cellcolor{green!25}0.000         &  \cellcolor{green!25}0.053           &  \cellcolor{green!25}0.000            &  \cellcolor{green!25}0.000            \\
		53         & 0.539        & 1.000         & 0.000         & 0.056           & 0.000            & 0.000            \\
		55         & 0.539        & 1.000         & 0.000         & 0.057           & 0.000            & 0.000            \\
		57         & 0.535        & 1.000         & 0.000         & 0.056           & 0.000            & 0.000            \\
		59         & 0.545        & 1.000         & 0.000         & 0.049           & 0.000            & 0.000            \\
		61         & 0.539        & 1.000         & 0.000         & 0.052           & 0.000            & 0.000            \\
		63         & 0.540        & 1.000         & 0.000         & 0.052           & 0.000            & 0.000            \\
		65         & 0.545        & 1.000         & 0.000         & 0.045           & 0.000            & 0.000            \\
		67         & 0.534        & 1.000         & 0.000         & 0.052           & 0.000            & 0.000            \\
		69         & 0.540        & 1.000         & 0.000         & 0.047           & 0.000            & 0.000            \\
		71         & 0.543        & 1.000         & 0.000         & 0.047           & 0.000            & 0.000            \\
		73         & 0.532        & 1.000         & 0.000         & 0.053           & 0.000            & 0.000            \\
		75         & 0.541        & 1.000         & 0.000         & 0.044           & 0.000            & 0.000            \\
		77         & 0.541        & 1.000         & 0.000         & 0.042           & 0.000            & 0.000            \\
		79         & 0.538        & 1.000         & 0.000         & 0.044           & 0.000            & 0.000            \\
		81         & 0.529        & 1.000         & 0.000         & 0.050           & 0.000            & 0.000            \\
		83         & 0.537        & 1.000         & 0.000         & 0.048           & 0.000            & 0.000           \\ \hline
		\caption{Delinquency Model Analysis K-NN}
		\label{Delinquency Model Analysis K-NN}
	\end{longtable}
}  

ROC was used to select the optimal model using  the largest value.

The final value used for the model was k = 51.

\begin{table}[H]
	\centering\
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l r r r r}
			\hline
			\textbf{Model} &  \textbf{Dataset} & \textbf{\# Bad} & \textbf{\# Good} & \textbf{\# Observations} & \textbf{Good:Bad} \\
			\hline
			Previous Delinquency & Training Synthetic K51 & 1,449 & 1,932 & 3,381 & 50:50\\
			& Test & 245 & 633 & 878 & 72:28\\\hline
			\textbf{Previous Previous Delinquency}     & \textbf{Total} & \textbf{1,694} & \textbf{2,565} & \textbf{4,259} & \textbf{60:40} \\
			\hline
			No Previous Delinquency & Training Synthetic K75 & 9,480 & 18,012 & 27,492 & 66:34 \\ 
			& Test & 177 & 7,070 & 7,247 & 97:03 	\\\hline
			\textbf{No Previous Delinquency}     & \textbf{Total} & \textbf{9,597} & \textbf{25,032} & \textbf{34,739} & \textbf{72:28} \\
			\hline
			\textbf{Total } 	&     	     & \textbf{11,291} & \textbf{27,597} & \textbf{38,998} & \textbf{71:29}\\ \hline
		\end{tabular}
	}
	\caption{Breakdown Holdout Training/Test Dataset \\for Synthetic Benchmark Models}
	\label{table:benchmark_holdout_Synthetic_train_test}
\end{table}


\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l l l r r r r}
			\hline
			\textbf{Model} & \textbf{Dataset} & \textbf{Software} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
			\textit{PD\_SyntheticBench\_R} & Previous Delinquency & R & 0.444 & 0.818 & 0.631 & 0.652   \\ \hline
			\textit{NPD\_SyntheticBench\_R} & No Previous Delinquency & R & 0.610 & 0.677 & 0.643 & 0.67   \\ \hline
		\end{tabular}
	}
	\caption{Benchmark Synthetic Model results for Comparison}
	\label{table:benchmodelSynthetic}
\end{table}

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{l  r r r r}
		\hline
		\textbf{Model} & \textbf{Recall} & \textbf{Specificity} & \textbf{BA} & \textbf{AUC}  \\ \hline
		\textit{PD\_SyntheticExper\_R}  & 0.444 & 0.803 & 0.624 & 0.650   \\ \hline
		\textit{NPD\_SyntheticExper\_R} & 0.621 & 0.656 & 0.639 & 0.669   \\ \hline
	\end{tabular}
	\caption{Experiment Oversampling Model Results for Experiment Comparison}
	\label{table:benchmodelSyntheticExper}
\end{table}



\section{Conclusion}
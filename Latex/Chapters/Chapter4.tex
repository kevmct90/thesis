% Chapter Template

\chapter{Experiment Implementation \& Evaluation} % Main chapter title

\label{Chapter4} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 4. \emph{Experiment Implementation \& Evaluation}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
\section{Introduction}
This chapter describes the experiment set-up and methodology for this project to predict if SME customers will go into arrears. The main theory being examined is that macro location based features/metrics can be indicative of SME's in the future going into arrears.  

There is relatively limited literature to support the location-based features chosen in this thesis, decisions are largely made due to anecdotal evidence and subject matter experts knowledge. To address this issue, empirical analysis of these features will be completed where one set of results will cascade new results and inspire further analysis. 

To understand if the location-based features in this analysis are useful, an initial model will be used as a baseline model from which we will look to improve iteratively. The features from this model will be derived from a historic scorecard used in \subjectname.  

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------
\section{Experiment Set-up}
This section will detail high level experimental information. In Fig. \ref{fig:experiment_setup} below SME accounts/customers are selected at the \textit{observation point}, June 2014. These accounts are not in default at this point in time. Information prior to the observation point will be used for modelling to predict if someone is likely to go into default, this can be termed the \textit{performance window}.

Data from each individual customers/accounts performance will be taken from data in the performance window time period, which will be combined with macro location-based data prior to the observation point also. This data will be aggregated and structured into features for an ABT. The aim will be that these features will be able to distinguish what customers/accounts are likely to default on there repayment in the next 12 months. 

\begin{figure}[h!]
	\includegraphics[width=0.8\textwidth,center]{experiment_setup}
	\caption[Experiment Performance Window and Outcome Window]
	{Experiment Performance Window and Outcome Window}
	\label{fig:experiment_setup}
\end{figure}

Previous, Section \ref{classLabelDef} described that there were two methods used to define if a customer was in default or not: (i) the \textit{worst status} label definition method; and (ii) the \textit{current status} label method approach. As mentioned previously, for the purpose of this experiment we will be using the industry standard worst status method, this means if the customers is in 90+ days arrears at any stage in the outcome window they will be labelled as a bad customer or as one that has defaulted on their financial obligation. 

\section{Baseline Benchmark in \subjectname\ }
When building a predictive model, the first thing you are trying to do is build a model which results/predictions are better than the \textit{no information rate}. This means the accuracy of the model must be better than the no information rate, which is taken to be the biggest class percentage in the data to be modelled.

For this research it would be redundant work/research to try and build a model that is better than the information rate as there are already models that exist in \subjectname\ for predicting arrears which can be leveraged. For this research the Risk team in \subjectname\ provided two feature sets that have used historically for predicting arrears \subjectname. They have segmented the data into two groups, \textit{Previous Delinquency} \& \textit{No Previous Delinquency}. After speaking with BE in the Risk function this was done because if a customer had been history of been delinquent this would become too dominant a feature in the model.

So two models will be built as baseline benchmarks which will be compared to the results of the experiment. One model will be based on a feature set for customers who have been delinquent in the past and the other feature set for customers who have not been in delinquent in the past. The customers will be modelled with these features first and results will be recorded. As part of the experiment location based features will be added to be modelled, with the aim that these features will statistically significant for predicting SME arrears. 

As mentioned before at the observation point, June 2014 SME accounts were selected that were not in default. These accounts are the basis for this experiment with a total a population size of is 27,082. 


\begin{table}[H]
	\centering\
	\resizebox{\textwidth}{!}
	{
	\begin{tabular}{l| l| r}
		\hline
		\textbf{Model} & \textbf{Status After Outcome Window June 2015} & \textbf{\# SME Customers} \\
		\hline
		Previous Delinquency          & In Default        & 728 \\
		Previous Delinquency          & Not in Default        & 2,198 \\ \hline
		No Previous Delinquency          & In Default        & 651 \\ 
		No Previous Delinquency          & Not In Default        & 23,505 \\
		\hline
		\textbf{Total Customers}         &         & \textbf{27,082} \\ \hline
	\end{tabular}
	}
	\caption{Base Model Account Detail}
\end{table}

As mentioned before the baseline model does not just need to be better than the no information rate but must to be representative of a model that could be deployed in \subjectname\ or any Financial Institution currently. As discussed in previous sections the financial institution model of choice is logistic regression, but for this research we will generate a baseline benchmark for other predictive models. These will all be generated using the exact same training, validation and test partitions in order to make a fair and valid comparison. 

\subsubsection{Previous Delinquency}

There are 11 features in the dataset to model customers who have been in default in the past. For security reasons the names and descriptions of these features could not be disclosed. The results for the baseline benchmarks models are as follows.
\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
	\begin{tabular}{l | r | r| r |r| r|r}
		\hline
		\textbf{Model} & \textbf{Train AUC} & \textbf{Train GINI} & \textbf{Valid AUC} & \textbf{Valid GINI}& \textbf{Test AUC} & \textbf{Test GINI}\\
		\hline
		\cellcolor{green!25}Gradient Boosting & \cellcolor{green!25}0.655 & \cellcolor{green!25}0.331 & \cellcolor{green!25}0.681 & \cellcolor{green!25}0.362 & \cellcolor{green!25}0.62 & \cellcolor{green!25}0.239 \\
		Dmine Regression & 0.678 & 0.356 & 0.674 & 0.349 & 0.61 & 0.22 \\
		Regression & 0.65 & 0.301 & 0.672 & 0.344 & 0.597 & 0.195 \\
		Regression Backstep & 0.643 & 0.287 & 0.661 & 0.323 & 0.6 & 0.2 \\
		Regression Forward Step & 0.643 & 0.287 & 0.661 & 0.323 & 0.6 & 0.2 \\
		Regression Both & 0.643 & 0.287 & 0.661 & 0.323 & 0.6 & 0.2 \\
		SVM Polynomial & 0.654 & 0.308 & 0.62 & 0.241 & 0.593 & 0.186 \\
		SVM Radial Basis Fn & 0.812 & 0.624 & 0.6 & 0.2 & 0.619 & 0.238 \\
		Decision Tree & 0.626 & 0.252 & 0.588 & 0.176 & 0.55 & 0.1 \\
		SVM Sigmoid & 0.492 & -0.016 & 0.511 & 0.241 & 0.023 & -0.018 \\
		\hline
	\end{tabular}
	}
	\caption{Previous Delinquency Base Benchmark Results}
	\label{table:prevdelinqbase}
\end{table}

The model that outputted the best result as seen table \ref{table:prevdelinqbase} highlighted in green above  was the Gradient Boosting Model, this is based on the highest validation AUC = 0.681. We can see above table \ref{table:prevdelinqbase} and Fig. \ref{fig:Delinq_Model_ROC} below that the \textit{Gradient Boosting Model} generalises quite well across the training, validation and testing partitions.

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{Base_Delinq_Model_ROC}
	\caption{Previous Delinquency Base Benchmark Model ROC Charts}
	\label{fig:Delinq_Model_ROC}
\end{figure}

It can be observed that this is not the case for the \textit{SVM Radial Basis Fn} model where it appears to have completely \textit{over-fitted} the training partition with an AUC training = 0.812 which drops to 0.60 and 0.619 for the validation and testing partitions datasets respectively. Overall most of the models appears to be predictive and have generalised quite well, however there may be case for investigating and removing the \textit{SVM Radial Basis Fn, Decision Tree and SVM Sigmoid} as these appear to not be predictive, not generalised well or to have over-fitted the training data partition. 

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{Base_Delinq_Model_Lift}
	\caption{Previous Delinquency Base Benchmark Model Lift Charts}
	\label{fig:Delinq_Model_Lift}
\end{figure}

We can see above in Fig. \ref{fig:Delinq_Model_Lift} that the majority of the models are returning positive results in the unseen test chart. This is very encouraging, for example if we were to contact 10\% of customers that these models decided were going to go into default, you would contact over twice as many customers that would go into default than if you used no model at all. This is very important when deciding on a business strategy and is where BE becomes extremely important. 

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.45\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,keepaspectratio]{Base_Delinq_Model_CutOff_Analysis_Default_50}\caption{Default Cut-Off = 0.50}\label{fig:Base_Delinq_Model_CutOff_Analysis_Default_50}
	\end{subfigure}  ~\quad
	\begin{subfigure}[b]{0.45\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,keepaspectratio]{Base_Delinq_Model_CutOff_Analysis_Min_Misclassification_Rate_48}
		\caption{Min Misclassification Rate Cut-Off = 0.48}\label{fig:Base_Delinq_Model_CutOff_Analysis_Min_Misclassification_Rate_54}
	\end{subfigure} 
	\medskip \newline
	\begin{subfigure}[b]{0.45\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,keepaspectratio]{Base_Delinq_Model_CutOff_Analysis_Event_KS_25}
		\caption{K-S Cut-Off = 0.25}\label{fig:Base_Delinq_Model_CutOff_Analysis_Event_KS_25}
	\end{subfigure} ~\quad
	\begin{subfigure}[b]{0.45\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,keepaspectratio]{Base_Delinq_Model_CutOff_Analysis_Event_Precision_Equal_Recall_29}
		\caption{EPER Cut-Off = 0.29}\label{fig:Base_Delinq_Model_CutOff_Analysis_Event_Precision_Equal_Recall_29}
	\end{subfigure}
	\caption{Delinquency Model Cut-off Analysis Confusion Matrix}
	\label{fig:Base_Delinq_Model_CutOff_Analysis_Event_Precision_Equal_Recall_33}
\end{figure}

As mentioned before knowing the business goal and aim can be very useful when trying to decide how you want to evaluate you model. The over usefulness and predictiveness of model can be got by combing the AUC with the ROC chart but sometimes this will not suffice. 

In Fig. \ref{fig:Base_Delinq_Model_CutOff_Analysis_Event_Precision_Equal_Recall_33} and Table \ref{table:DelinquencyModelCutoff} you can see the cut-off analysis for the best benchmark model \textit{Gradient Boosting}. As discussed in \ref{Chapter2} this analysis demonstrates that depending on your business goal you may want to maximise or minimise some performance measure over another.

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
	\begin{tabular}{l|l|r|r|r|r|r|r|r|r|r|r}
		\hline
		\textbf{Cut-off} & \textbf{Method}       & \textbf{TP} & \textbf{FP} & \textbf{FN} & \textbf{TN} & \textbf{Accuracy} & \textbf{Precision} & \textbf{NPV} & \textbf{Recall} & \textbf{Specificity} & \textbf{MR} \\ \hline
		0.5              & Default (Train)       & 23          & 6           & 413         & 1312        & 0.761             & 0.793              & 0.761        & 0.053           & 0.995                & 0.239       \\
		0.5              & Default (Valid)       & 8           & 1           & 138         & 439         & 0.763             & 0.889              & 0.761        & 0.055           & 0.998                & 0.237       \\
		0.5              & Default (Test)        & 9           & 1           & 137         & 439         & 0.765             & 0.900              & 0.762        & 0.062           & 0.998                & 0.235       \\ \hline
		0.48             & Min MR (Train)        & 34          & 13          & 402         & 1305        & 0.763             & 0.723              & 0.764        & 0.078           & 0.990                & 0.237       \\
		0.48             & Min MR (Valid)        & 9           & 5           & 137         & 435         & \cellcolor{yellow!25}0.758             & \cellcolor{yellow!25}0.643              & 0.760        & 0.062           & \cellcolor{yellow!25}0.989                & \cellcolor{yellow!25}0.242       \\
		0.48             & Min MR (Test)         & 10          & 2           & 136         & 438         & 0.765             & 0.833              & 0.763        & 0.068           & 0.995                & 0.235       \\ \hline
		0.25             & K-S (Train) & 244         & 405         & 192         & 913         & 0.660             & 0.376              & 0.826        & 0.560           & 0.693                & 0.340       \\
		0.25             & K-S (Valid) & 80          & 130         & 66          & 310         & 0.666             & 0.381              & \cellcolor{yellow!25}0.824        & \cellcolor{yellow!25}0.548           & 0.705                & 0.334       \\
		0.25             & K-S (Test)  & 74          & 145         & 72          & 295         & 0.630             & 0.338              & 0.804        & 0.507           & 0.670                & 0.370       \\ \hline
		0.29             & EPER (Train)          & 178         & 246         & 258         & 1072        & 0.713             & 0.420              & 0.806        & 0.408           & 0.813                & 0.287       \\
		0.29             & EPER (Valid)          & 54          & 81          & 92          & 359         & 0.705             & 0.400              & 0.796        & 0.370           & 0.816                & 0.295       \\
		0.29             & EPER (Test)           & 50          & 87          & 96          & 353         & 0.688             & 0.365              & 0.786        & 0.342           & 0.802                & 0.312      \\ \hline
	\end{tabular}
	}
	\caption{Delinquency Model Cut-off Results }
	\label{table:DelinquencyModelCutoff}
\end{table}

\subsubsection{No Previous Delinquency}

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l | r | r| r |r| r|r}
			\hline
			\textbf{Model} & \textbf{Train AUC} & \textbf{Train GINI} & \textbf{Valid AUC} & \textbf{Valid GINI}& \textbf{Test AUC} & \textbf{Test GINI}\\
			\hline
			 \cellcolor{green!25}Regression & \cellcolor{green!25}0.695 & \cellcolor{green!25}0.389 & \cellcolor{green!25}0.71 & \cellcolor{green!25}0.419 & \cellcolor{green!25}0.677 & \cellcolor{green!25}0.354 \\
			Regression Backstep & 0.691 & 0.381 & 0.706 & 0.413 & 0.678 & 0.357 \\
			Regression Forward Step & 0.691 & 0.381 & 0.706 & 0.413 & 0.678 & 0.357 \\
			Regression Both & 0.691 & 0.381 & 0.706 & 0.413 & 0.678 & 0.357 \\
			Gradient Boosting & 0.653 & 0.305 & 0.683 & 0.366 & 0.688 & 0.336 \\
			Dmine Regression & 0.649 & 0.297 & 0.67 & 0.34 & 0.628 & 0.255 \\
			SVM Radial Fn & 0.591 & 0.182 & 0.558 & 0.116 & 0.512 & 0.025 \\
			SVM Sigmoid & 0.605 & 0.21 & 0.549 & 0.099 & 0.588 & 0.176 \\
			Decision Tree & 0.5 & 0 & 0.5 & 0 & 0.5 & 0 \\
			SVM Polynomial & 0.477 & -0.046 & 0.497 & -0.007 & 0.487 & -0.026 \\
			\hline
		\end{tabular}
	}
	\caption{No Previous Delinquency Base Model Details}
\end{table}


\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{Base_NonDelinq_Model_ROC}
	\caption{No Previous Delinquency Model ROC Chart}
	\label{fig:NonDelinq_Model_ROC}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=0.9\textwidth,center]{Base_NonDelinq_Model_Lift}
	\caption{No Previous Delinquency Model Lift Chart}
	\label{fig:NonDelinq_Model_Lift}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{ 0.45\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,keepaspectratio]{Base_Non_Delinq_Model_CutOff_Analysis_Default_50}\caption{Default Cut-Off = 0.50}\label{fig:Base_Non_Delinq_Model_CutOff_Analysis_Default_50}
	\end{subfigure}  ~\quad
	\begin{subfigure}[b]{0.45\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,keepaspectratio]{Base_Non_Delinq_Model_CutOff_Analysis_Min_Misclassification_Rate_21}
		\caption{Min Misclassification Cut-Off= 0.21}\label{fig:Base_Non_Delinq_Model_CutOff_Analysis_Min_Misclassification_Rate_17}
	\end{subfigure} 
	\medskip \newline
	\begin{subfigure}[b]{0.45\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,keepaspectratio]{Base_Non_Delinq_Model_CutOff_Analysis_Event_KS_0269}
		\caption{K-S Cut-Off = 0.026}\label{fig:Base_Non_Delinq_Model_CutOff_Analysis_Event_KS_026}
	\end{subfigure} ~\quad
	\begin{subfigure}[b]{0.45\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,keepaspectratio]{Base_Non_Delinq_Model_CutOff_Analysis_Event_Precision_Equal_Recall_08}
		\caption{EPER Cut-Off = 0.08}\label{fig:Base_Non_Delinq_Model_CutOff_Analysis_Event_Precision_Equal_Recall_09}
	\end{subfigure}
	\caption{Non Delinquency Model Cut-Off Analysis}
	\label{fig:balanced_corr_analysis}
\end{figure}

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
	\begin{tabular}{l|l|r|r|r|r|r|r|r|r|r|r}
		\hline
		\textbf{Cut-off} & \textbf{Method} & \textbf{TP} & \textbf{FP} & \textbf{FN} & \textbf{TN} & \textbf{Accuracy} & \textbf{Precision} & \textbf{NPV} & \textbf{Recall} & \textbf{Specificity} & \textbf{MR} \\ \hline
		0.5             & Default (Train) & 0           & 0           & 391         & 14103       & 0.973             & NA                 & 0.973        & 0.000           & 1.000                & 0.027       \\
		0.5             & Default (Valid) & 0           & 0           & 130         & 4701        & 0.973             & NA                 & 0.973        & 0.000           & 1.000                & 0.027       \\
		0.5             & Default (Test)  & 0           & 0           & 130         & 4701        & 0.973             & NA          & 0.973        & 0.000           & 1.000                & 0.027       \\ \hline
		0.21            & Min MR (Train)  & 1           & 17          & 390         & 14086       & 0.972             & 0.056              & 0.973        & 0.003           & 0.999                & 0.028       \\
		0.21            & Min MR (Valid)  & 0           & 6           & 130         & 4695        & \cellcolor{yellow!25}0.972             & 0.000              & 0.973        & 0.000           & \cellcolor{yellow!25}0.999                & \cellcolor{yellow!25}0.028       \\
		0.21            & Min MR (Test)   & 1           & 4           & 129         & 4697        & 0.972             & 0.200              & 0.973        & 0.008           & 0.999                & 0.028       \\ \hline
		0.03            & K-S (Train)     & 208         & 3583        & 183         & 10520       & 0.740             & 0.055              & 0.983        & 0.532           & 0.746                & 0.260       \\
		0.03            & K-S (Valid)      & 70          & 1182        & 60          & 3519        & 0.743             & 0.056              & \cellcolor{yellow!25}0.983        & \cellcolor{yellow!25}0.538           & 0.749                & 0.257       \\
		0.03            & K-S (Test)     & 67          & 1199        & 63          & 3502        & 0.739             & 0.053              & 0.982        & 0.515           & 0.745                & 0.261       \\ \hline
		0.08            & EPER (Train)    & 65          & 464         & 326         & 13639       & 0.945             & 0.123              & 0.977        & 0.166           & 0.967                & 0.055       \\
		0.08            & EPER (Valid)    & 19          & 167         & 111         & 4534        & 0.942             & \cellcolor{yellow!25}0.102              & 0.976        & 0.146           & 0.964                & 0.058       \\
		0.08            & EPER (Test)     & 21          & 173         & 109         & 4528        & 0.942             & 0.108              & 0.976        & 0.162           & 0.963                & 0.058     \\ \hline
	\end{tabular}
	}
	\caption{My caption}
	\label{my-label}
\end{table}

\section{Feature Selection}
With respect to creating a model that could be utilised in real time, reduction of dimensionality is of key importance. Generating all of the 400 metrics used in the initial model based on on-going session activity would be very complex to implement in practice. A feature selection process was implemented at this point to reduce the complexity of the dataset. 

\subsection{Correlation Analysis}

\begin{figure}[H]
	\centering
		\begin{subfigure}[b]{0.32\textwidth}
			\captionsetup{font=scriptsize}
			\includegraphics[width=\textwidth,height=2.75cm]{Grouped_Features_Correlation_Analysis_Subset}\caption{Grouped Features}\label{fig:groupedFeaturesCorrelation}
		\end{subfigure} 
		\begin{subfigure}[b]{0.32\textwidth}
			\captionsetup{font=scriptsize}
			\includegraphics[width=\textwidth,height=2.75cm]{SME_Arrears_Trends_Correlation_Analysis_Subset}
			\caption{SME Arrears Trends}\label{fig:smeArrearsCorrelation}
		\end{subfigure} 
		\begin{subfigure}[b]{0.32\textwidth}
			\captionsetup{font=scriptsize}
			\includegraphics[width=\textwidth,height=2.75cm]{Personal_Arrears_Ratio}
			\caption{Personal Arrears}\label{fig:personalArrearsCorrelation}
		\end{subfigure} 
	\medskip
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Visa_Debit_Correlation_Analysis_Subset}
		\caption{Transactions}\label{fig:transVisaCorrelation}
	\end{subfigure} ~\quad
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{CSO_Correlation_Analysis}
		\caption{CSO}\label{fig:CSOCorrelation}
	\end{subfigure}
\caption{Unbalanced Correlation Analysis}
\label{fig:unbal_corr_analysis}
\end{figure}
	
\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Balanced_Grouped_Features_Correlation_Analysis_Subset}\caption{Grouped Features}\label{fig:groupedFeaturesCorrelation}
	\end{subfigure} 
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Balanced_SME_Arrears_Trends_Correlation_Analysis_Subset}
		\caption{SME Arrears Trends}\label{fig:smeArrearsCorrelation}
	\end{subfigure} 
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Balanced_Personal_Arrears_Ratio}
		\caption{Personal Arrears}\label{fig:personalArrearsCorrelation}
	\end{subfigure} 
	\medskip
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Balanced_Visa_Debit_Correlation_Analysis_Subset}
		\caption{Transactions}\label{fig:transVisaCorrelation}
	\end{subfigure} ~\quad
	\begin{subfigure}[b]{0.32\textwidth}
		\captionsetup{font=scriptsize}
		\includegraphics[width=\textwidth,height=2.75cm]{Balanced_CSO_Correlation_Analysis}
		\caption{CSO}\label{fig:CSOCorrelation}
	\end{subfigure}
	\caption{Balanced Correlation Analysis}
	\label{fig:balanced_corr_analysis}
\end{figure}


\subsection{Stepwise Analysis}

\section{Binning / Coarse Classification}

\section{Addressing Imbalance}
\subsection{Undersampling}
\subsection{Oversampling}

\section{Comparing Results of Various Experiments}

\section{Model Selection/Validation}

\section{Interpretation of Results}

\section{Evaluation of Experiments}

\section{Conclusion}
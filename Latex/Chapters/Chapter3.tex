% Chapter Template

\chapter{Data} % Main chapter title

\label{Chapter3} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 3. \emph{Data}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
\section{Introduction}
This chapter presents the data that will be used for the experiments to be carried out in this research and will be split into two major sections. 

The first section will outline where the customers for the experiment have been gathered and under what criteria they have been selected. As part of the experiment a baseline predictive model will be built, this will be done using features that were used in historic industry credit scorecard models in \subjectname. Performance measure measure will selected evaluated also using this base line analysis.

The second section will outline what macro-economic features will be used as part of the research in the experiment. The aim of this research is to investigate the predictive power of macro-economic features by geographic regions such as electoral divisions and local authority in Ireland. To do this addresses are stored in \subjectname's databases are queried against an search engine built for this research and mapped to \textit{Global Positioning System} (GPS) coordinates string metric algorithms. The macro-economic features will be sourced internally in \subjectname\ and externally from open data sources. It will also explain how these features have been created, what transformations or data wrangling had to be done so the features fit/map into an analytical base table (ABT) discussed in Section \ref{sec:datasetConstruction} that is a requirement for predictive modelling.

\section{Customers for Credit Scoring and Existing Features}

The customer data used for prediction in these experiments was sourced from a financial institution \subjectname which is one of the two main pillar banks in Ireland. It contains details of 27,082 SME customers who were active between June 2014 and June 2015. These 27,082 customers are a subset of SME customers on the \subjectname\ book as the experiment will only be completed on one of the loan systems in the financial institution. 

As mentioned in Section \ref{sec:segment} it is very common in credit scoring to model the population into multiple groups. This is done so homogeneous customers are grouped and model together based on for example pattern, characteristic, demographic etc.


\begin{table}[H]
	\centering\
	\resizebox{\textwidth}{!}
	{
		\begin{tabular}{l r r r r r r}
			\hline
			\textbf{Model} &  \textbf{\# Numeric} & \textbf{\# Nominal} & \textbf{\# Observations} & \textbf{\# Good} & \textbf{\# Bad} & \textbf{Good:Bad}\\
			\hline
			Previous Delinquency & 11 & 0 & 2,926 & 2,198  & 738 & 75:25 \\ 
			No Previous Delinquency & 9 & 0 & 24,156 & 23,505 & 651  & 97:03 \\ \hline
			\textbf{Total} &  &  & \textbf{27,082} & \textbf{25,703} & \textbf{1,389} & \textbf{95:05} \\ \hline
		\end{tabular}
	}
	\caption{Characteristics of datasets to be used in the exploratory evaluation for training a baseline model and assessing the evaluation metrics to be used in the research \\
		 \# Numeric refers to the number of continuous features \\
		 \# Nominal refers to the number of categorical features
		}
\end{table}



\section{Data for Experiment}


The vast majority of the data required for the experiment already exists on a Teradata warehouse within Lender A. Therefore, most of the data required for the modelling should be easily accessible. In some cases the data will need to be derived for the model, and this is certainly the case with the derived spending habits from the transactional data for each mortgage.
The different data items required for the predictive model will be sourced from a number of different entities from within the data warehouse including the Customer, Application, Mortgage, Transaction and Account entities. Each of these entities are generally fed from separate source systems, that exist as separate entities outside of the warehouse with their own rules and integrity constraints. As a result there may be some referential integrity issues with the data, but for the purposes of this experiment only data that meets all existing referential criteria within the warehouse will be included in the data utilised. Any data for whatever reason is believed to be incorrect in terms of referential integrity will not be included in any model generation.
59
For the purposes of this experiment, each mortgage will be taken in its entirety. In some cases a mortgage may have multiple loan accounts associated with it, as a mortgage may be split across a number of different products or a borrower may have received a top-up loan or released equity from the property. A classic example of this is where a customer has a mortgage for \euro 350,000 with the mortgage split across two loan accounts, one on a fixed rate, with the other portion on a tracker or variable rate. For the purposes of this experiment, this will be treated as one mortgage, though in some cases this may be reported as two mortgages, especially when reporting on mortgage types. By rolling up the mortgage accounts associated with each property it will be ensured that each property will only be included once in the analysis.
A mortgage must have at least one customer associated with it, though there can be multiple customers associated with one mortgage. The most common number of customers associated with a mortgage is two, though mortgages can exist with three or four customers associated with them. For the purposes of the data items that are at a customer level any of the numeric variables such as salary will be aggregated, so that the mortgage total will be a sum of all the constituent customers associated with the mortgage. An example of this would be the total salary for each customer. If there are multiple customers associated with a mortgage, then the mortgage level salary will be an aggregation of the individual customer salaries. For other values such as the age of the customers associated with the mortgage the minimum, maximum as well as the mean values for all associated customers will be used.
Similarly for data items that are currently held at account level these will be rolled up to mortgage level, so that the mortgage representation will be a summation of all the values associated with the constituent accounts. Some examples of this include the balance on the mortgage as well as the outstanding arrears amount where applicable.


\section{Old Sections}
This chapter will detail the design of the experiments that are to be implemented as part of the research project. It will detail how customers addresses are mapped to locations and how features are generated for these locations. It will also discuss any of the pre-processing, and feature selection and statistical techniques used to create select the data for the ABT.

The SME default problem would be considered imbalanced dataset for classification problem where algorithms make the assumption there is a equal number of good and bad classes/group \citep{japkowicz_class_2000}. The dataset used in this experiment has a small number of SME customer in default, because of this issue a number of approaches will taken to considered to address.

Statistical analysis and evaluation methods used to assess the strength of models will be detailed and discussed, also it will outline any further transformations necessary for specific algorithms. Finally criteria for deciding which model will be chosen as the best and most fit for purpose will be detailed.

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------
\section{Data for Research and Data Preparation}
This research project will combine data from an existing scorecard in \subjectname\ with location based data. There will be three new sources of location based data for this experiment. They are as follows......

\subsection{Existing Data in \subjectname's Model}

\subsection{Electoral Division and Local Authority Classification}
\begin{itemize}
	\item \subjectname's Customers Transactional behaviour by location.
	\item \subjectname\ default ratio by location.
	\item CSO metrics captured using the 2011 census. 
\end{itemize}

Locations for this research will be found using \subjectname's customer addresses. These will be cleansed to be standardised them and will put through a search engine built using Solr. The top 10 results are returned using Solr, a matching algorithms are then ran to compare the searched address and returned results. The two distance formulas used to compare the are the following \textit{Levenshtein distance} and the \textit{Jaro-Winkler distance}.

\subsection{Mapping Addresses using Apache Solr}


\begin{figure}[h!]
	\includegraphics[width=0.8\textwidth,center]{Solr_Example_Search}
	\caption[Query Example and Syntax]
	{Query Example and Syntax}
	\label{fig:Solr_Example_Search}
\end{figure}

\begin{figure}[h!]
	\includegraphics[width=0.8\textwidth,center]{Solr_Inverted_Index}
	\caption[Illustration of Inverted Indexing]
	{Illustration of Inverted Indexing}
	\label{fig:Solr_Inverted_Index}
\end{figure}

\subsubsection{Levenshtein Distance}
Mathematically, the Levenshtein distance between two strings \textit{a}, \textit{b} (of length \text{\textbar}a\text{\textbar} and \text{\textbar}b\text{\textbar} respectively) is given by lev$_{a,b}$ (\text{\textbar}a\text{\textbar},\text{\textbar}b\text{\textbar}) where
\begin{align}
	lev_{a,b}(i,j) = 
	\begin{cases}
		\max(i,j) & \text{ if} \min(i,j)=0, \\
		\min \begin{cases}
			\operatorname{lev}_{a,b}(i-1,j) + 1 \\
			\operatorname{lev}_{a,b}(i,j-1) + 1 \\
			\operatorname{lev}_{a,b}(i-1,j-1) + 1_{(a_i \neq b_j)}
		\end{cases} & \text{ otherwise.}
	\end{cases}
\end{align}
where $1_{(a_i \neq b_j)}$ is the indicator function equal to $0$ when $a_i = b_j$ and equal to 1 otherwise, and $\operatorname{lev}_{a,b}(i,j)$ is the distance between the first $i$ characters of $a$ and the first $j$ characters of $b$.

\subsubsection{Jaro-Winkler Distance}
The Jaro distance $d_j$ of two given strings $s_1$ and $s_2$ is
 
\begin{align}
 d_j =\begin{cases}
 \begin{array}{l l}
 	0 & \text{if }m = 0\\
 	\frac{1}{3}\left(\frac{m}{|s_1|} + \frac{m}{|s_2|} + \frac{m-t}{m}\right) & \text{otherwise} \end{array} \end{cases}
\end{align}

Where: 
\vspace{-7mm} 
\begin{itemize}
	\item $m$ is the number of matching characters 
 	\item $t$ is half the number of transpositions
\end{itemize}

\subsubsection{Examples}
Give example of how addresses are cleansed, standardised, searched and results are calculated.

\subsection{Visa Debit Transactional Data}
\subsubsection{Discretionary Non-Discretionary Categorisation}

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
	\label{my-label}
	\begin{tabular}{|l|l|l|l|}
		\hline
		\textbf{MCC Category} & \textbf{Parent}          & \textbf{Child}                 & \textbf{Spend / Live} \\ \hline
		2.2                   & Bills \& Utilities       & Cable/Satellite TV \& Internet & Spend                 \\ \hline
		2.7                   & Bills \& Utilities       & Gas/Electricity/Energy         & Live                  \\ \hline
		3.1                   & Leisure \& Entertainment & Cinema \& Theatre              & Spend                 \\ \hline
		4.1                   & Shopping                 & Groceries                     & Live                  \\ \hline
		4.4                   & Shopping                 & Clothing \& Accessories        & Spend                 \\ \hline
		5.2                   & Health \& Personal Care  & Doctor                         & Live                  \\ \hline
		5.6                   & Health \& Personal Care  & Hair \& Beauty                 & Spend                 \\ \hline
		6.2                   & Household/Home           & Household Maintenance          & Live                  \\ \hline
		6.5                   & Household/Home           & Computers \& Technology        & Spend                 \\ \hline
	\end{tabular}
	}
	\caption{Spend Live Categorisation }
\end{table}



\subsubsection{Percentage Change}

\begin{align}
\text{Percentage Change} = \frac{X^{2} - X^{1}}{X^{1}}*100  
\end{align}
Where: 
\vspace{-7mm} 
\begin{itemize}
	\item $X^{1} = $ the original variable
	\item $X^{2} = $ the new variable
\end{itemize}


\subsection{Electoral Division and Local Authority}
\textbf{Local Authorities}
In census reports the country is divided into 29 counties/administrative counties and the five Cities which represent the
local authority areas. Outside Dublin there are 26 administrative counties (North Tipperary and South Tipperary each
ranks as a separate county for administrative purposes) and four Cities, i.e. Cork, Limerick, Waterford and Galway. In
Dublin the four local authority areas are identified separately, i.e. Dublin City and the three administrative counties of
Dún Laoghaire-Rathdown, Fingal and South Dublin.

\textbf{Electoral Divisions}
There are 3,440 Electoral Divisions (EDs) which are the smallest legally defined administrative areas in the State. One ED, St. Mary's, straddles the Louth-Meath county border, and is presented in two parts in the SAPS1 tables, with one part in Louth and the other in Meath. There are 32 EDs with low population, which for reasons of confidentiality have been amalgamated into neighbouring EDs giving a total of 3,409 EDs which appear in the SAPS tables.

\begin{table}[H]
	\centering
	\label{my-label}
	\begin{tabular}{|l|l|p{10cm}|}
		\hline
		\textbf{Feature} & \textbf{Data Type} & \textbf{Description}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \\ \hline
		ED\_ID           & Categorical        & There are 3,440 Electoral Divisions (EDs) which are the smallest legally defined administrative areas in Ireland.                                                                                                                                                                                                                                                                                                                                                                             \\ \hline
		LA\_ID           & Categorical        & In census reports the country is divided into 29 counties/administrative counties and the five Cities which represent the local authority areas. Outside Dublin there are 26 administrative counties (North Tipperary and South Tipperary each ranks as a separate county for administrative purposes) and four Cities, i.e. Cork, Limerick, Waterford and Galway. In Dublin the four local authority areas are identified separately, i.e. Dublin City and the three administrative counties of Dun Laoghaire-Rathdown, Fingal and South Dublin. \\ \hline
	\end{tabular}
	\caption{Electoral Division and Local Authority Details }
\end{table}


\subsection{Census 2011 Ireland}
The Census gives a comprehensive picture of the social and living conditions of the population in 2011. It provides detail to the smallest area and the results are an essential tool for effective policy, planning and decision making purposes. 

The data is organised around a number of themes (see below) and broken down by a range of geographic areas as
described below.

Themes of data available in the census data.
\begin{table}[H]
	\centering
	\label{my-label}
	\begin{tabular}{|l|l|}
		\hline
		\textbf{Theme Number} & \textbf{Theme Description} \\ \hline
		Theme 1    & Sex, age and marital status \\ \hline
		Theme 2    & Migration, ethnicity and religion \\ \hline
		Theme 3    & Irish Language \\ \hline
		Theme 4    & Families \\ \hline
		Theme 5    & Private Household \\ \hline
		Theme 6    & Housing \\ \hline
		Theme 7	   & Communal establishments \\ \hline
		Theme 8    & Principal status \\ \hline
		Theme 9    & Social class and socio-economic group \\ \hline
		Theme 10   & Education \\ \hline
		Theme 11   & Commuting \\ \hline	
		Theme 12   & Disability, careers and general health \\ \hline		
		Theme 13   & Occupation \\ \hline
		Theme 14   & Industries \\ \hline
		Theme 15   & PC and internet Access \\ \hline			
	\end{tabular}
	\caption{Lending Product Classification }
\end{table}


\url{http://www.cbs.gov.il/census/census/pnimi_sub_page_e.html?id_topic=1&id_subtopic=5}

\begin{table}[H]
	\centering
	\label{my-label}
	\begin{tabular}{|l|l|}
		\hline
		\textbf{Product Summary Description} & \textbf{Product Detailed Description} \\ \hline
		Branch Advances     & Fixed Loans \\ \hline
		Branch Advances     & Matrix Loans \\ \hline
		Branch Advances     & Other Loans \\ \hline
		Branch Advances     & Premium Business Rate \\ \hline
		Branch Advances     & Prime Loans \\ \hline
		Branch Advances     & Staff Credit Flex \\ \hline
		Branch Advances		& Suspense Interest \\ \hline
		Home Loan           & Buy to Let \\ \hline
		Home Loan           & Commercial Mortgages \\ \hline
		Home Loan           & Home Loan \\ \hline
		Home Loan           & Staff Homeflex \\ \hline
		Home Loan           & Standard Mortgages \\ \hline	
		Home Loan           & Surplus Builder \\ \hline		
		Home Loan           & Tracker Mortgages \\ \hline		
	\end{tabular}
	\caption{CSO Theme Breakdown}
\end{table}

\subsubsection{Principal Status/Employment}
\subsubsection{Occupation}
\subsubsection{Education}
Lower than Upper Secondary Education
A question I wanted to address was there was areas with higher concentrations of lower education by ED and LA, and if this had any correlations with SME arrears in \subjectname.

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
	\label{my-label}
	\begin{tabular}{|l |l|}
		\hline
		\textbf{Education Levels}                                   & \textbf{Lower than Upper Secondary Education} \\ \hline
		No Formal Education                                         & Yes                                           \\ \hline
		Primary Education                                           & Yes                                           \\ \hline
		Lower Secondary                                             & Yes                                           \\ \hline
		Upper Secondary                                             & No                                            \\ \hline
		Technical or Vocational qualification                       & No                                            \\ \hline
		Advanced Certificate/Completed Apprenticeship               & No                                            \\ \hline
		Higher Certificate                                          & No                                            \\ \hline
		Ordinary Bachelor Degree or National Diploma                & No                                            \\ \hline
		Honours Bachelor Degree, Professional Qualification or both & No                                            \\ \hline
		Postgraduate Diploma or Degree                              & No                                            \\ \hline
		Doctorate(Ph.D) or higher                                   & No                                            \\ \hline
		Not Stated                                                  & NA                                            \\ \hline
	\end{tabular}
	}
	\caption{My caption}
\end{table}

\subsection{Arrears Ratio for \subjectname\ Personal Customers}
\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}
	{
	\label{my-label}
	\begin{tabular}{|l|l|l|}
		\hline
		\textbf{Feature} & \textbf{Data Type} & \textbf{Description}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \\ \hline
		ED\_Arrears\_Ratio          & Interval        & Percentage of personal customers in a ED to be in arrears.                                                                                                                                                                                                                                                                                                                                                                           \\ \hlineß
		LA\_Arrears\_Ratio           & Interval        & Percentage of personal customers in a LA to be in arrears \\ \hline
	\end{tabular}
	}
	\caption{Arrears Ratio for \subjectname\ Personal Customers }
\end{table}

\begin{table}[H]
	\centering
	\label{my-label}
	\resizebox{\textwidth}{!}
	{
	\begin{tabular}{|l|l|l|l|}
		\hline
		\textbf{Product Summary Description} & \textbf{Product Detailed Description} \\ \hline
		Branch Advances     & Fixed Loans \\ \hline
		Branch Advances     & Matrix Loans \\ \hline
		Branch Advances     & Other Loans \\ \hline
		Branch Advances     & Premium Business Rate \\ \hline
		Branch Advances     & Prime Loans \\ \hline
		Branch Advances     & Staff Credit Flex \\ \hline
		Branch Advances		& Suspense Interest \\ \hline
		Home Loan           & Buy to Let \\ \hline
		Home Loan           & Commercial Mortgages \\ \hline
		Home Loan           & Home Loan \\ \hline
		Home Loan           & Staff Homeflex \\ \hline
		Home Loan           & Standard Mortgages \\ \hline	
		Home Loan           & Surplus Builder \\ \hline		
		Home Loan           & Tracker Mortgages \\ \hline		
	\end{tabular}
	}
	\caption{Lending 
		Product Classification }
\end{table}

\subsection{Generating the ABTs}
We now have a reference list that allows us to apply a rank to all achievable loan application events prior to completion. A method is required to join this reference list with our csv (comma seperated value) log files resulting from the MapReduce job. 

%Fine from here
\subsection{Software Used}\label{softwareUsed}

\subsubsection{Address Matching}
A combination of Apache Solr\footnote{\url{http://lucene.apache.org/solr/}} and Python\footnote{\url{https://www.python.org/}} were used to match \subjectname's addresses to an ED/LA in GDD. Solr ia an open source web application enterprise search engine. It is an open source application written in Java, which is a wrapper around the Apache Lucence \footnote{{\url{https://lucene.apache.org/core/}}}. Combined they provide a reliable, fast, scalable platform capable of providing distributed indexing which can then be used for searching or navigation. Solr was used to index GD which then allowed it to be searched. Python is a high-level, general purpose programming language which can be used to build both large and small scale programs. Python like Solr is open source and freely available. One its most attractive and best characteristics is it is easy to read and use. A program was created to standardise and cleanse the addresses in \subjectname's database. The program would then take the cleansed addresses and query them against GDD indexed through the Solr web API, using string comparison algorithms discussed in Chapter 2 to return the most likely GDD address.

\subsubsection{Data Wrangling}
Anecdotally speaking, data scientists and analysts spend majority of their time data wrangling. Data wrangling is time consuming mundane process used to collect and prepare data prior to being explored for useful information. In the experiment of this thesis a variety of data types and data sources were used. Data from the \subjectname\ EDW, GDD in Solr served in JSON, CSO data in flat file to name a few. R\footnote{{\url{https://www.r-project.org/}}}, another open source programming language but has much more emphasis on statistical computing. It also has many libraries available for processing and data manipulation which are available in the CRAN\footnote{{\url{https://cran.r-project.org/}}} repository. The most useful package used during this process was \textit{reshape}\footnote{{\url{https://cran.r-project.org/web/packages/reshape/index.html}}}. Reshape allows to easily restructure, transpose and aggregate your data. 

\subsubsection{Visualisations}
R is also a very strong programming language at creating beautiful visualisations so it will be used throughout this paper. One package used in this paper was \textit{ggplot}
\footnote{{\url{https://cran.r-project.org/web/packages/ggplot2/index.html}}}. 

Some other custom geospatial visualisations may also be required. This could be done using Arcgis, Qgis, D3 or R still to be decided.

\subsubsection{Modelling}
SQL was used to identify customers to be used for predictions and generate the target class.
The models and experiments performed in this used in this are built in R and SAS. SAS is a proprietary software. SAS is the tool of choice by the modelling teams in \subjectname. Anecdotally SAS is a legacy in financial institutions, it is what people are used to using but also there is a for-profit corporation vetting the code for its customers and customer service and support corporations are used to. SAS offers a graphical interfaces which means users do not have to enter code, but this can be complemented using the SAS programming language. Anecdotally speaking SAS is excellent for building predictive modes resulting in good time to value. SAS Enterprise Miner includes the following components Time Series, Variable Clustering, Cluster, Interactive Binning, Principal Components, AutoNeural, DMNeural, DMine Regression, Gradient Boosting, Ensemble, and Text Mining.
\\
R is a very strong competitor to SAS in this space. Because of its open source nature there are many libraries available for building predictive models. For example one popular package \textit{caret}\footnote{{\url{https://cran.r-project.org/web/packages/caret/index.html}}} contains many models and continues to grow

\section{Building Models}
In order to avoid over-fitting models, considerations need to be made as to what data to use in training the model. Each of the models built will be trained using a training set which is a subset of the over all available samples. We discussed possible options for training set selection in subsection


\section{Evaluation Methods}
Several evaluation techniques will be applied to quantify the usefulness of all models produced. As discussed in section \ref{modelEval}, there are various ways to evaluate the performance of a classifier. A common metric used is overall accuracy (\% of records correctly classified). 


\section{Conclusions}\label{desConc}
\begin{comment}
This chapter has discussed the processes required to carry out data mining techniques on non-relational web log data. The required data transformations have been discussed as well as the implemented methods for feature generation.
\end{comment}